{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "fTNAQ1tj8t0s",
        "mSEuyaMSqegO",
        "Ul4atpoEq9uK",
        "63UZSK4NlWum"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fe9ce525717147579951bf9a2ee604c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea7e6d3b99c14e6c8dd0d90d9c889833",
              "IPY_MODEL_bdfd8be8dfb64fa6bb4488852e0349d4",
              "IPY_MODEL_b5dc5f66647e48b386bd038ec3d6e770"
            ],
            "layout": "IPY_MODEL_599802674ce446aca475c1e943f1dadd"
          }
        },
        "ea7e6d3b99c14e6c8dd0d90d9c889833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c5c1a91cd31439cb9c6cb5e2ccac56f",
            "placeholder": "​",
            "style": "IPY_MODEL_8f9e989b79ad48a397c25280e06e42cb",
            "value": "Processing 0.05% center of video: 100%"
          }
        },
        "bdfd8be8dfb64fa6bb4488852e0349d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7df8a0b7f464286ae524ba5d820ac36",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d8b941b46de4c18a5ca64a57a986760",
            "value": 2
          }
        },
        "b5dc5f66647e48b386bd038ec3d6e770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8baab977c7aa4481a657c29acfa75ba9",
            "placeholder": "​",
            "style": "IPY_MODEL_fa649fe84d1142319bb264073a834dfb",
            "value": " 2/2 [00:02&lt;00:00,  1.05s/it]"
          }
        },
        "599802674ce446aca475c1e943f1dadd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c5c1a91cd31439cb9c6cb5e2ccac56f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f9e989b79ad48a397c25280e06e42cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7df8a0b7f464286ae524ba5d820ac36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d8b941b46de4c18a5ca64a57a986760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8baab977c7aa4481a657c29acfa75ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa649fe84d1142319bb264073a834dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b5fec85ed544088aea10f0690f9f53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8ea9d33778340f5983cbe95086cdf7b",
              "IPY_MODEL_6c3abf11074d4972a4b6b6f501728f38",
              "IPY_MODEL_f8e8c2cd3b16484fabaed06b237f5859"
            ],
            "layout": "IPY_MODEL_a53af95a867e4fec8dc06145175079f8"
          }
        },
        "c8ea9d33778340f5983cbe95086cdf7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1f66efd65a442aa85ad8b8b6c7259a5",
            "placeholder": "​",
            "style": "IPY_MODEL_8bd47e9049f3451e8af0cfe7d49d5f84",
            "value": "100%"
          }
        },
        "6c3abf11074d4972a4b6b6f501728f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc8415c571c54d65a01eb30e50481ae5",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18994428e34644debd16c9779c51775a",
            "value": 150
          }
        },
        "f8e8c2cd3b16484fabaed06b237f5859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a0e1931ac254a8ca6f7731fff53df21",
            "placeholder": "​",
            "style": "IPY_MODEL_2e769ee6b39249d1af2f7f99a920aab0",
            "value": " 150/150 [00:47&lt;00:00,  3.32it/s]"
          }
        },
        "a53af95a867e4fec8dc06145175079f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1f66efd65a442aa85ad8b8b6c7259a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bd47e9049f3451e8af0cfe7d49d5f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc8415c571c54d65a01eb30e50481ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18994428e34644debd16c9779c51775a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a0e1931ac254a8ca6f7731fff53df21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e769ee6b39249d1af2f7f99a920aab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63f8825faece466a9566c53625887ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbe6fb2f8b78419a884c8b6ff1470ff5",
              "IPY_MODEL_2d5dc18d23264abf8f7124b69647ae69",
              "IPY_MODEL_5571668f90f44c07bbed6da334eb863e"
            ],
            "layout": "IPY_MODEL_b2511e84f9f143ee8d71c40159d6c643"
          }
        },
        "bbe6fb2f8b78419a884c8b6ff1470ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f3ce161f53844568be3fdc52112d598",
            "placeholder": "​",
            "style": "IPY_MODEL_e82dbdae8e3641d6b158924dace72459",
            "value": "100%"
          }
        },
        "2d5dc18d23264abf8f7124b69647ae69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20c7dfa01da742a4a6b8456244cc6e21",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35c989b54b3847ea981aca252cd8d1f3",
            "value": 1000
          }
        },
        "5571668f90f44c07bbed6da334eb863e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7df3d1410a1d4abeadaab6253d678567",
            "placeholder": "​",
            "style": "IPY_MODEL_c46bc61d52b84b8985046e8e323deeb4",
            "value": " 1000/1000 [12:24&lt;00:00,  1.31it/s]"
          }
        },
        "b2511e84f9f143ee8d71c40159d6c643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f3ce161f53844568be3fdc52112d598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e82dbdae8e3641d6b158924dace72459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20c7dfa01da742a4a6b8456244cc6e21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35c989b54b3847ea981aca252cd8d1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7df3d1410a1d4abeadaab6253d678567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c46bc61d52b84b8985046e8e323deeb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-mCm4TNg8tN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# БИБЛИОТЕКИ (install)"
      ],
      "metadata": {
        "id": "fTNAQ1tj8t0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Удаляем старые версии MMCV, если есть\n",
        "!pip uninstall -y mmcv mmcv-full\n",
        "!pip install numpy==1.26.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NgUbd7nS_no4",
        "outputId": "ab45e717-3399-4049-89b0-9bedb63afa01"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: mmcv 2.1.0\n",
            "Uninstalling mmcv-2.1.0:\n",
            "  Successfully uninstalled mmcv-2.1.0\n",
            "\u001b[33mWARNING: Skipping mmcv-full as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jCli3K_2we1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "830c5b65-30d7-4313-87c6-f881550725a2",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch==2.0.1+cu118 in /usr/local/lib/python3.11/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision==0.15.2+cu118 in /usr/local/lib/python3.11/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (2.28.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (11.2.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1+cu118) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (3.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1+cu118) (1.3.0)\n",
            "Requirement already satisfied: openmim in /usr/local/lib/python3.11/dist-packages (0.3.9)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.11/dist-packages (from openmim) (8.2.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from openmim) (0.4.6)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.11/dist-packages (from openmim) (0.1.11)\n",
            "Requirement already satisfied: opendatalab in /usr/local/lib/python3.11/dist-packages (from openmim) (0.0.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from openmim) (2.2.2)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.11/dist-packages (from openmim) (24.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from openmim) (2.28.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from openmim) (13.4.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from openmim) (0.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from model-index->openmim) (6.0.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from model-index->openmim) (3.8.2)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.11/dist-packages (from model-index->openmim) (4.1.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim) (3.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim) (4.65.2)\n",
            "Requirement already satisfied: openxlab in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (3.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (2025.6.15)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->openmim) (1.17.0)\n",
            "Requirement already satisfied: filelock~=3.14.0 in /usr/local/lib/python3.11/dist-packages (from openxlab->opendatalab->openmim) (3.14.0)\n",
            "Requirement already satisfied: oss2~=2.17.0 in /usr/local/lib/python3.11/dist-packages (from openxlab->opendatalab->openmim) (2.17.0)\n",
            "Requirement already satisfied: packaging~=24.0 in /usr/local/lib/python3.11/dist-packages (from openxlab->opendatalab->openmim) (24.2)\n",
            "Requirement already satisfied: setuptools~=60.2.0 in /usr/local/lib/python3.11/dist-packages (from openxlab->opendatalab->openmim) (60.2.0)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.11/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (1.7)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.16.5)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.11/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.16.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.22)\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n",
            "Requirement already satisfied: mmengine in /usr/local/lib/python3.11/dist-packages (0.10.7)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from mmengine) (2.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmengine) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmengine) (1.26.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from mmengine) (6.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from mmengine) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from mmengine) (3.1.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from mmengine) (0.43.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.11/dist-packages (from mmengine) (4.11.0.86)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine) (2.9.0.post0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine) (2.19.2)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->mmengine) (4.3.8)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.17.0)\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n",
            "Collecting mmcv<2.2.0,>=2.0.1\n",
            "  Using cached https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/mmcv-2.1.0-cp311-cp311-manylinux1_x86_64.whl (98.6 MB)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from mmcv<2.2.0,>=2.0.1) (2.4.0)\n",
            "Requirement already satisfied: mmengine>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from mmcv<2.2.0,>=2.0.1) (0.10.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmcv<2.2.0,>=2.0.1) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mmcv<2.2.0,>=2.0.1) (24.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from mmcv<2.2.0,>=2.0.1) (11.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from mmcv<2.2.0,>=2.0.1) (6.0.2)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from mmcv<2.2.0,>=2.0.1) (0.43.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.11/dist-packages (from mmcv<2.2.0,>=2.0.1) (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.3.0->mmcv<2.2.0,>=2.0.1) (3.10.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.3.0->mmcv<2.2.0,>=2.0.1) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.3.0->mmcv<2.2.0,>=2.0.1) (3.1.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->mmcv<2.2.0,>=2.0.1) (4.3.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.1) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.1) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.1) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.1) (2.9.0.post0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.1) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.1) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.1) (1.17.0)\n",
            "Installing collected packages: mmcv\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mmpose 1.3.2 requires mmdet<3.3.0,>=3.0.0; extra == \"mim\", but you have mmdet 3.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mmcv-2.1.0\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n",
            "Requirement already satisfied: mmpose>=1.1.0 in ./mmpose (1.3.2)\n",
            "Collecting xtcocotools@ git+https://github.com/jin-s13/xtcocoapi (from mmpose>=1.1.0)\n",
            "  Cloning https://github.com/jin-s13/xtcocoapi to /tmp/pip-install-ijla_l36/xtcocotools_7a1cd2877ed64de8b61a401e491ff850\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/jin-s13/xtcocoapi /tmp/pip-install-ijla_l36/xtcocotools_7a1cd2877ed64de8b61a401e491ff850\n",
            "  Resolved https://github.com/jin-s13/xtcocoapi to commit d74033ff1635e9002133b2380862bc2b728584d2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Ignoring mmcv: markers 'extra == \"mim\"' don't match your environment\n",
            "Ignoring mmdet: markers 'extra == \"mim\"' don't match your environment\n",
            "Ignoring mmengine: markers 'extra == \"mim\"' don't match your environment\n",
            "Requirement already satisfied: chumpy in /usr/local/lib/python3.11/dist-packages (from mmpose>=1.1.0) (0.70)\n",
            "Requirement already satisfied: json_tricks in /usr/local/lib/python3.11/dist-packages (from mmpose>=1.1.0) (3.17.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmpose>=1.1.0) (3.10.0)\n",
            "Requirement already satisfied: munkres in /usr/local/lib/python3.11/dist-packages (from mmpose>=1.1.0) (1.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmpose>=1.1.0) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from mmpose>=1.1.0) (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from mmpose>=1.1.0) (11.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from mmpose>=1.1.0) (1.15.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from mmpose>=1.1.0) (0.15.2+cu118)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from chumpy->mmpose>=1.1.0) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmpose>=1.1.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmpose>=1.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmpose>=1.1.0) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmpose>=1.1.0) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmpose>=1.1.0) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmpose>=1.1.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmpose>=1.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision->mmpose>=1.1.0) (2.28.2)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.11/dist-packages (from torchvision->mmpose>=1.1.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision->mmpose>=1.1.0) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision->mmpose>=1.1.0) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision->mmpose>=1.1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision->mmpose>=1.1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision->mmpose>=1.1.0) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision->mmpose>=1.1.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision->mmpose>=1.1.0) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision->mmpose>=1.1.0) (18.1.8)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.11/dist-packages (from xtcocotools@ git+https://github.com/jin-s13/xtcocoapi->mmpose>=1.1.0) (60.2.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.11/dist-packages (from xtcocotools@ git+https://github.com/jin-s13/xtcocoapi->mmpose>=1.1.0) (3.0.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->mmpose>=1.1.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->mmpose>=1.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->mmpose>=1.1.0) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->mmpose>=1.1.0) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1->torchvision->mmpose>=1.1.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1->torchvision->mmpose>=1.1.0) (1.3.0)\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html\n",
            "Requirement already satisfied: mmdet>=3.1.0 in /usr/local/lib/python3.11/dist-packages (3.3.0)\n",
            "Ignoring mmcv: markers 'extra == \"mim\"' don't match your environment\n",
            "Ignoring mmengine: markers 'extra == \"mim\"' don't match your environment\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmdet>=3.1.0) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmdet>=3.1.0) (1.26.4)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from mmdet>=3.1.0) (2.0.10)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from mmdet>=3.1.0) (1.15.3)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from mmdet>=3.1.0) (2.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from mmdet>=3.1.0) (1.17.0)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.11/dist-packages (from mmdet>=3.1.0) (3.1.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mmdet>=3.1.0) (4.65.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmdet>=3.1.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmdet>=3.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmdet>=3.1.0) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmdet>=3.1.0) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmdet>=3.1.0) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmdet>=3.1.0) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmdet>=3.1.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmdet>=3.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.163)\n",
            "Requirement already satisfied: deep-sort-realtime in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.28.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.65.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (18.1.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "fatal: destination path 'mmpose' already exists and is not an empty directory.\n",
            "/content/mmpose\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements/build.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from -r requirements/build.txt (line 3)) (2.0.1+cu118)\n",
            "Requirement already satisfied: chumpy in /usr/local/lib/python3.11/dist-packages (from -r requirements/runtime.txt (line 1)) (0.70)\n",
            "Requirement already satisfied: json_tricks in /usr/local/lib/python3.11/dist-packages (from -r requirements/runtime.txt (line 2)) (3.17.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements/runtime.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: munkres in /usr/local/lib/python3.11/dist-packages (from -r requirements/runtime.txt (line 4)) (1.1.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements/runtime.txt (line 6)) (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements/runtime.txt (line 7)) (11.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements/runtime.txt (line 8)) (1.15.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements/runtime.txt (line 9)) (0.15.2+cu118)\n",
            "Requirement already satisfied: xtcocotools>=1.12 in /usr/local/lib/python3.11/dist-packages (from -r requirements/runtime.txt (line 10)) (1.14.3)\n",
            "Requirement already satisfied: coverage in /usr/local/lib/python3.11/dist-packages (from -r requirements/tests.txt (line 1)) (7.9.2)\n",
            "Requirement already satisfied: flake8 in /usr/local/lib/python3.11/dist-packages (from -r requirements/tests.txt (line 2)) (7.3.0)\n",
            "Requirement already satisfied: interrogate in /usr/local/lib/python3.11/dist-packages (from -r requirements/tests.txt (line 3)) (1.7.0)\n",
            "Requirement already satisfied: isort==4.3.21 in /usr/local/lib/python3.11/dist-packages (from -r requirements/tests.txt (line 4)) (4.3.21)\n",
            "Requirement already satisfied: parameterized in /usr/local/lib/python3.11/dist-packages (from -r requirements/tests.txt (line 5)) (0.9.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from -r requirements/tests.txt (line 6)) (8.3.5)\n",
            "Requirement already satisfied: pytest-runner in /usr/local/lib/python3.11/dist-packages (from -r requirements/tests.txt (line 7)) (6.0.1)\n",
            "Requirement already satisfied: xdoctest>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements/tests.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from -r requirements/tests.txt (line 9)) (0.43.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r requirements/optional.txt (line 1)) (2.28.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->-r requirements/build.txt (line 3)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->-r requirements/build.txt (line 3)) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->-r requirements/build.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->-r requirements/build.txt (line 3)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->-r requirements/build.txt (line 3)) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->-r requirements/build.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.8->-r requirements/build.txt (line 3)) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.8->-r requirements/build.txt (line 3)) (18.1.8)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from chumpy->-r requirements/runtime.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements/runtime.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements/runtime.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements/runtime.txt (line 3)) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements/runtime.txt (line 3)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements/runtime.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements/runtime.txt (line 3)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements/runtime.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.11/dist-packages (from xtcocotools>=1.12->-r requirements/runtime.txt (line 10)) (60.2.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.11/dist-packages (from xtcocotools>=1.12->-r requirements/runtime.txt (line 10)) (3.0.12)\n",
            "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from flake8->-r requirements/tests.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pycodestyle<2.15.0,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from flake8->-r requirements/tests.txt (line 2)) (2.14.0)\n",
            "Requirement already satisfied: pyflakes<3.5.0,>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from flake8->-r requirements/tests.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from interrogate->-r requirements/tests.txt (line 3)) (25.3.0)\n",
            "Requirement already satisfied: click>=7.1 in /usr/local/lib/python3.11/dist-packages (from interrogate->-r requirements/tests.txt (line 3)) (8.2.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from interrogate->-r requirements/tests.txt (line 3)) (0.4.6)\n",
            "Requirement already satisfied: py in /usr/local/lib/python3.11/dist-packages (from interrogate->-r requirements/tests.txt (line 3)) (1.11.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from interrogate->-r requirements/tests.txt (line 3)) (0.9.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->-r requirements/tests.txt (line 6)) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->-r requirements/tests.txt (line 6)) (1.6.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->-r requirements/tests.txt (line 9)) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements/optional.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements/optional.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements/optional.txt (line 1)) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements/optional.txt (line 1)) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->-r requirements/build.txt (line 3)) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.8->-r requirements/build.txt (line 3)) (1.3.0)\n",
            "Using pip 24.1.2 from /usr/local/lib/python3.11/dist-packages/pip (python 3.11)\n",
            "Obtaining file:///content/mmpose\n",
            "  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-h_3wlprp/mmpose.egg-info\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-h_3wlprp/mmpose.egg-info/SOURCES.txt'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-h_3wlprp/mmpose.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting xtcocotools@ git+https://github.com/jin-s13/xtcocoapi (from mmpose==1.3.2)\n",
            "  Cloning https://github.com/jin-s13/xtcocoapi to /tmp/pip-install-1px6hek1/xtcocotools_29d7c8c588eb473db27d7ac2d4062a6f\n",
            "  Running command git version\n",
            "  git version 2.34.1\n",
            "  Running command git clone --filter=blob:none https://github.com/jin-s13/xtcocoapi /tmp/pip-install-1px6hek1/xtcocotools_29d7c8c588eb473db27d7ac2d4062a6f\n",
            "  Cloning into '/tmp/pip-install-1px6hek1/xtcocotools_29d7c8c588eb473db27d7ac2d4062a6f'...\n",
            "  Running command git rev-parse HEAD\n",
            "  d74033ff1635e9002133b2380862bc2b728584d2\n",
            "  Resolved https://github.com/jin-s13/xtcocoapi to commit d74033ff1635e9002133b2380862bc2b728584d2\n",
            "  Running command git rev-parse HEAD\n",
            "  d74033ff1635e9002133b2380862bc2b728584d2\n",
            "  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-eif8ar6k/xtcocotools.egg-info\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-eif8ar6k/xtcocotools.egg-info/SOURCES.txt'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-eif8ar6k/xtcocotools.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: chumpy in /usr/local/lib/python3.11/dist-packages (from mmpose==1.3.2) (0.70)\n",
            "Requirement already satisfied: json_tricks in /usr/local/lib/python3.11/dist-packages (from mmpose==1.3.2) (3.17.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmpose==1.3.2) (3.10.0)\n",
            "Requirement already satisfied: munkres in /usr/local/lib/python3.11/dist-packages (from mmpose==1.3.2) (1.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmpose==1.3.2) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from mmpose==1.3.2) (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from mmpose==1.3.2) (11.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from mmpose==1.3.2) (1.15.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from mmpose==1.3.2) (0.15.2+cu118)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from chumpy->mmpose==1.3.2) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmpose==1.3.2) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmpose==1.3.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmpose==1.3.2) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmpose==1.3.2) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmpose==1.3.2) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmpose==1.3.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmpose==1.3.2) (2.9.0.post0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision->mmpose==1.3.2) (2.28.2)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.11/dist-packages (from torchvision->mmpose==1.3.2) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision->mmpose==1.3.2) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision->mmpose==1.3.2) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision->mmpose==1.3.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision->mmpose==1.3.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision->mmpose==1.3.2) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchvision->mmpose==1.3.2) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision->mmpose==1.3.2) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision->mmpose==1.3.2) (18.1.8)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.11/dist-packages (from xtcocotools@ git+https://github.com/jin-s13/xtcocoapi->mmpose==1.3.2) (60.2.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.11/dist-packages (from xtcocotools@ git+https://github.com/jin-s13/xtcocoapi->mmpose==1.3.2) (3.0.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->mmpose==1.3.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->mmpose==1.3.2) (3.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->mmpose==1.3.2) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->mmpose==1.3.2) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1->torchvision->mmpose==1.3.2) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1->torchvision->mmpose==1.3.2) (1.3.0)\n",
            "Installing collected packages: mmpose\n",
            "  Attempting uninstall: mmpose\n",
            "    Found existing installation: mmpose 1.1.0\n",
            "    Uninstalling mmpose-1.1.0:\n",
            "      Removing file or directory /usr/local/lib/python3.11/dist-packages/mmpose-1.1.0.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.11/dist-packages/mmpose/\n",
            "      Successfully uninstalled mmpose-1.1.0\n",
            "  Running setup.py develop for mmpose\n",
            "    Running command python setup.py develop\n",
            "    running develop\n",
            "    /usr/local/lib/python3.11/dist-packages/setuptools/command/easy_install.py:156: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
            "      warnings.warn(\n",
            "    /usr/local/lib/python3.11/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "      warnings.warn(\n",
            "    running egg_info\n",
            "    writing manifest file 'mmpose.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "Successfully installed mmpose-1.3.2\n",
            "/content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n",
            "Успешный импорт!\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 \\\n",
        "    --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# 2. Устанавливаем openmim (менеджер MMLab-пакетов), mmengine и совместимую версию mmcv\n",
        "!pip install -U openmim\n",
        "!mim install mmengine\n",
        "!mim install \"mmcv>=2.0.1,<2.2.0\"\n",
        "\n",
        "# 3. Устанавливаем MMPose (версия 1.x) и MMDetection\n",
        "!mim install \"mmpose>=1.1.0\"\n",
        "!mim install \"mmdet>=3.1.0\"\n",
        "\n",
        "# 4. Устанавливаем DeepSort and OpenCV and YOLO\n",
        "!pip install ultralytics deep-sort-realtime opencv-python\n",
        "!git clone https://github.com/open-mmlab/mmpose.git\n",
        "%cd mmpose\n",
        "!pip install scipy tqdm mmpose==1.1.0 deep_sort_realtime --quiet\n",
        "!pip install -r requirements.txt\n",
        "!pip install -v -e .\n",
        "%cd ..\n",
        "\n",
        "import torch\n",
        "from mmpose.apis import init_model, inference_topdown\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "print(torch.__version__)\n",
        "print(\"Успешный импорт!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from mmpose.apis import init_model, inference_topdown\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "\n",
        "print(torch.__version__)  # Должен быть 2.x\n",
        "print(\"Успешный импорт!\")\n"
      ],
      "metadata": {
        "id": "HZA84LsXwhSu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a757fee3-d545-4fac-ead6-a2a5f10d9ff0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n",
            "Успешный импорт!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mXJgOtGxqLmn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# yolo11n-pose"
      ],
      "metadata": {
        "id": "mSEuyaMSqegO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "# Путь к видео\n",
        "youtube_video_path = \"/content/input_video.mp4\"\n",
        "per_sent = 5\n",
        "# Загрузка модели YOLO11-pose (nano-версия для скорости)\n",
        "model = YOLO(\"yolo11n-pose.pt\")\n",
        "\n",
        "# Функция для получения длительности видео\n",
        "def get_video_duration(video_path):\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"Error: Video file {video_path} not found\")\n",
        "        return 0, 0\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    duration = total_frames / fps if fps > 0 else 0\n",
        "    cap.release()\n",
        "    return duration, fps\n",
        "\n",
        "# Функция для обработки 10% видео\n",
        "def process_video_segment(video_path, output_path, segment_percentage=per_sent / 100):\n",
        "    # Проверка существования файла\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"Error: Video file {video_path} not found\")\n",
        "        return 0\n",
        "\n",
        "    # Получение длительности и FPS\n",
        "    total_duration, fps = get_video_duration(video_path)\n",
        "    if total_duration == 0:\n",
        "        return 0\n",
        "\n",
        "    # Вычисление длительности сегмента (10%)\n",
        "    segment_duration = total_duration * segment_percentage\n",
        "    print(f\"Total video duration: {total_duration:.2f} seconds\")\n",
        "    print(f\"Processing segment duration: {segment_duration:.2f} seconds\")\n",
        "\n",
        "    # Открытие видео\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Настройка сохранения результата\n",
        "    output_video_path = os.path.join(output_path, f\"segment_output({per_sent}%).mp4\")\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "    start_time = time.time()\n",
        "    frame_count = 0\n",
        "    max_frames = int(segment_duration * fps)\n",
        "\n",
        "    while cap.isOpened() and frame_count < max_frames:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Обработка кадра с помощью YOLO11-pose\n",
        "        results = model.track(frame, persist=True, tracker=\"bytetrack.yaml\")\n",
        "\n",
        "        # Визуализация результатов\n",
        "        annotated_frame = results[0].plot()  # Добавляет bounding boxes, ключевые точки и ID треков\n",
        "        out.write(annotated_frame)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Подсчет FPS\n",
        "    inference_time = end_time - start_time\n",
        "    processed_fps = frame_count / inference_time if inference_time > 0 else 0\n",
        "\n",
        "    # Вывод результатов\n",
        "    print(f\"Processed {frame_count} frames\")\n",
        "    print(f\"Inference time: {inference_time:.2f} seconds\")\n",
        "    print(f\"Average FPS: {processed_fps:.2f}\")\n",
        "\n",
        "    # Извлечение ключевых точек и ID треков для первого кадра (пример)\n",
        "    if results and len(results) > 0:\n",
        "        print(f\"Keypoints (xy): {results[0].keypoints.xy}\")\n",
        "        print(f\"Track IDs: {results[0].boxes.id}\")\n",
        "\n",
        "    # Закрытие видео\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(f\"Output saved to {output_video_path}\")\n",
        "\n",
        "    return processed_fps\n",
        "\n",
        "# Создание директории для результатов\n",
        "output_dir = \"/content/output\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Обработка N% видео\n",
        "print(f\"Processing N% of video: {youtube_video_path}\")\n",
        "fps = process_video_segment(youtube_video_path, output_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQCauttcqiFQ",
        "outputId": "3d9eb188-3ef5-4f4a-91cf-a24eccb64c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing N% of video: /content/input_video.mp4\n",
            "Total video duration: 215.16 seconds\n",
            "Processing segment duration: 10.76 seconds\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['lap>=0.5.12'] not found, attempting AutoUpdate...\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 0.6s\n",
            "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "0: 384x640 (no detections), 117.0ms\n",
            "Speed: 2.1ms preprocess, 117.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.4ms\n",
            "Speed: 2.8ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 2.7ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.6ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.4ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.3ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.6ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.7ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 6.2ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.4ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.4ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 2.4ms preprocess, 17.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.4ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.3ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.4ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.4ms preprocess, 9.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 2.4ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.5ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.6ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.3ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.4ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 3.0ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.5ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.4ms preprocess, 9.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.6ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 3.0ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 1.9ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.5ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 4.1ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.5ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.5ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.5ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.5ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.3ms\n",
            "Speed: 2.3ms preprocess, 16.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 5.8ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.4ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 2.3ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.3ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.4ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 2.3ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.6ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.2ms\n",
            "Speed: 2.6ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.4ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.3ms\n",
            "Speed: 2.9ms preprocess, 14.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.6ms\n",
            "Speed: 3.3ms preprocess, 15.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.6ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.4ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.5ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 2.7ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.7ms\n",
            "Speed: 2.5ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.6ms preprocess, 9.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.5ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.6ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.5ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.4ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.6ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.6ms\n",
            "Speed: 3.8ms preprocess, 17.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.7ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.3ms\n",
            "Speed: 2.3ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.2ms\n",
            "Speed: 2.5ms preprocess, 17.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 2.3ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 2.6ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.7ms\n",
            "Speed: 2.6ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.2ms\n",
            "Speed: 2.5ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 2.6ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 2.5ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 2.5ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.7ms\n",
            "Speed: 2.5ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.6ms\n",
            "Speed: 2.4ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.3ms\n",
            "Speed: 2.4ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.8ms\n",
            "Speed: 2.6ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 4.4ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.7ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 2.7ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 4.1ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.4ms\n",
            "Speed: 2.4ms preprocess, 17.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 2.5ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 2.7ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 2.6ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 2.9ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.3ms\n",
            "Speed: 2.5ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 2.7ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 2.5ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 20.4ms\n",
            "Speed: 2.4ms preprocess, 20.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 23.8ms\n",
            "Speed: 2.4ms preprocess, 23.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 22.1ms\n",
            "Speed: 3.2ms preprocess, 22.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.0ms\n",
            "Speed: 3.4ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.1ms\n",
            "Speed: 2.5ms preprocess, 18.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.9ms\n",
            "Speed: 2.8ms preprocess, 16.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.2ms\n",
            "Speed: 3.9ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.9ms\n",
            "Speed: 5.6ms preprocess, 13.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.3ms\n",
            "Speed: 2.9ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.3ms\n",
            "Speed: 3.0ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.9ms\n",
            "Speed: 3.2ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 2.8ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.9ms\n",
            "Speed: 2.8ms preprocess, 13.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 4.9ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.9ms\n",
            "Speed: 2.5ms preprocess, 15.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.1ms\n",
            "Speed: 2.5ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.2ms\n",
            "Speed: 2.5ms preprocess, 16.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 2.6ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.3ms\n",
            "Speed: 2.5ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.6ms\n",
            "Speed: 2.5ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 19.5ms\n",
            "Speed: 3.9ms preprocess, 19.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 19.7ms\n",
            "Speed: 2.5ms preprocess, 19.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.5ms\n",
            "Speed: 2.5ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.8ms\n",
            "Speed: 4.8ms preprocess, 18.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.7ms\n",
            "Speed: 2.5ms preprocess, 18.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.4ms\n",
            "Speed: 2.4ms preprocess, 17.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.1ms\n",
            "Speed: 2.5ms preprocess, 17.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.6ms\n",
            "Speed: 2.5ms preprocess, 16.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.4ms\n",
            "Speed: 2.5ms preprocess, 17.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 19.9ms\n",
            "Speed: 2.6ms preprocess, 19.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 2.5ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.6ms\n",
            "Speed: 3.0ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.8ms\n",
            "Speed: 2.5ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.8ms\n",
            "Speed: 2.6ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 2.8ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 2.5ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 2.5ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 2.7ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 2.6ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.1ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.5ms\n",
            "Speed: 3.2ms preprocess, 14.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.9ms\n",
            "Speed: 2.7ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.5ms\n",
            "Speed: 3.8ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 2.7ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 1.9ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.7ms\n",
            "Speed: 2.4ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.3ms\n",
            "Speed: 4.3ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.1ms\n",
            "Speed: 2.6ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.7ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 2.4ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.8ms\n",
            "Speed: 3.3ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 2.6ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 2.7ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 2.7ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 2.7ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 2.7ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.6ms\n",
            "Speed: 1.9ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.3ms\n",
            "Speed: 2.7ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.4ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 2.5ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 2.5ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.4ms\n",
            "Speed: 3.7ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 3.6ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.6ms\n",
            "Speed: 2.7ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.8ms\n",
            "Speed: 2.7ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 2.6ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.7ms\n",
            "Speed: 2.6ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.6ms\n",
            "Speed: 2.7ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.2ms\n",
            "Speed: 2.4ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 2.5ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed 268 frames\n",
            "Inference time: 12.57 seconds\n",
            "Average FPS: 21.32\n",
            "Keypoints (xy): tensor([[[ 437.5419,  265.9025],\n",
            "         [ 444.9278,  236.6973],\n",
            "         [ 403.2538,  241.3611],\n",
            "         [ 436.7584,  242.1168],\n",
            "         [ 327.0875,  256.2079],\n",
            "         [ 457.6173,  388.1853],\n",
            "         [ 244.0124,  399.5092],\n",
            "         [ 494.1465,  586.4617],\n",
            "         [ 152.2141,  606.7532],\n",
            "         [ 514.4094,  674.0286],\n",
            "         [ 150.2479,  705.9604],\n",
            "         [ 416.8518,  720.0000],\n",
            "         [ 277.8646,  720.0000],\n",
            "         [ 435.2240,  706.1051],\n",
            "         [ 254.7200,  720.0000],\n",
            "         [ 384.8484,  720.0000],\n",
            "         [ 234.5000,  720.0000]],\n",
            "\n",
            "        [[ 878.7045,  271.3798],\n",
            "         [ 901.6078,  246.1893],\n",
            "         [ 856.2289,  245.9146],\n",
            "         [ 937.1931,  261.4392],\n",
            "         [ 825.0496,  260.7494],\n",
            "         [1006.1608,  410.0467],\n",
            "         [ 759.6223,  399.6597],\n",
            "         [1055.1287,  592.1707],\n",
            "         [ 663.6644,  571.3757],\n",
            "         [ 965.5306,  630.6649],\n",
            "         [ 752.0876,  641.3357],\n",
            "         [ 963.3768,  712.4924],\n",
            "         [ 799.9965,  707.9894],\n",
            "         [ 975.9651,  720.0000],\n",
            "         [ 780.0681,  716.8008],\n",
            "         [ 955.0291,  720.0000],\n",
            "         [ 782.3829,  720.0000]],\n",
            "\n",
            "        [[1125.1543,  288.7443],\n",
            "         [1154.4772,  267.4103],\n",
            "         [1103.3929,  262.6960],\n",
            "         [1194.6785,  290.0177],\n",
            "         [1071.7278,  280.7155],\n",
            "         [1239.6794,  424.5488],\n",
            "         [1032.9564,  420.3289],\n",
            "         [1223.3198,  594.6188],\n",
            "         [1021.9581,  585.1348],\n",
            "         [1083.5533,  621.1577],\n",
            "         [1057.6970,  623.1210],\n",
            "         [1198.6915,  713.7303],\n",
            "         [1056.7885,  707.9485],\n",
            "         [1189.2877,  720.0000],\n",
            "         [1021.3364,  720.0000],\n",
            "         [1144.9368,  720.0000],\n",
            "         [1030.8894,  720.0000]],\n",
            "\n",
            "        [[ 261.5331,  206.3018],\n",
            "         [ 267.3593,  184.7967],\n",
            "         [ 229.1119,  196.1852],\n",
            "         [ 272.1253,  205.9333],\n",
            "         [ 180.6930,  238.7746],\n",
            "         [ 328.2747,  337.2905],\n",
            "         [ 137.2664,  366.6100],\n",
            "         [ 362.2502,  467.6367],\n",
            "         [  52.9769,  506.1989],\n",
            "         [ 280.2086,  485.3159],\n",
            "         [   0.0000,  580.1578],\n",
            "         [ 288.1609,  663.8667],\n",
            "         [ 163.9857,  671.5520],\n",
            "         [ 258.8403,  720.0000],\n",
            "         [ 111.5084,  720.0000],\n",
            "         [ 199.7564,  720.0000],\n",
            "         [  74.4146,  720.0000]]], device='cuda:0')\n",
            "Track IDs: tensor([1., 2., 3., 5.])\n",
            "Output saved to /content/output/segment_output(5%).mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ai3rdzRolVoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Faster R-CNN + DeepSort + HRNet"
      ],
      "metadata": {
        "id": "Ul4atpoEq9uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Подключаем библиотеки и модели\n",
        "\n",
        "\n",
        "import glob, scipy.io, torch, torchvision, cv2, numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from mmpose.apis import init_model, inference_topdown\n",
        "\n",
        "# --- Устройство ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- Детектор: Faster R-CNN ---\n",
        "detector = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT').to(device)\n",
        "detector.eval()\n",
        "\n",
        "# --- Трекинг: DeepSort ---\n",
        "tracker = DeepSort(max_age=5)\n",
        "\n",
        "# --- Поза: HRNet ---\n",
        "pose_config = 'mmpose/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-256x192.py'\n",
        "pose_checkpoint = 'hrnet_w48_coco_256x192.pth'\n",
        "if not os.path.exists(pose_checkpoint):\n",
        "    !wget -q https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth -O hrnet_w48_coco_256x192.pth\n",
        "pose_model = init_model(pose_config, pose_checkpoint, device=device)\n",
        "#___| don't change |__"
      ],
      "metadata": {
        "id": "ewc86-_x_4uX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08fd3302-7f42-4874-9282-e76a424a5e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
            "100%|██████████| 160M/160M [00:00<00:00, 235MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loads checkpoint by local backend from path: hrnet_w48_coco_256x192.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mmpose/mmpose/datasets/datasets/utils.py:102: UserWarning: The metainfo config file \"configs/_base_/datasets/coco.py\" does not exist. A matched config file \"/content/mmpose/mmpose/.mim/configs/_base_/datasets/coco.py\" will be used instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "import os, cv2, time\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from mmpose.apis import init_model, inference_topdown\n",
        "\n",
        "# --- Устройство ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- Детектор: Faster R-CNN ---\n",
        "detector = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT').to(device)\n",
        "detector.eval()\n",
        "\n",
        "# --- Трекинг: DeepSort ---\n",
        "tracker = DeepSort(max_age=5,n_init=1)\n",
        "\n",
        "# --- Поза: HRNet ---\n",
        "pose_config = 'mmpose/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-256x192.py'\n",
        "pose_checkpoint = 'hrnet_w48_coco_256x192.pth'\n",
        "if not os.path.exists(pose_checkpoint):\n",
        "    !wget -q https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth -O hrnet_w48_coco_256x192.pth\n",
        "pose_model = init_model(pose_config, pose_checkpoint, device=device)\n"
      ],
      "metadata": {
        "id": "4WsG504MCTJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35040cda-91f7-47f6-cf16-75a3b6e43657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loads checkpoint by local backend from path: hrnet_w48_coco_256x192.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "N = 0.05\n",
        "# --- Путь к видео ---\n",
        "video_path = '/content/input_video.mp4'\n",
        "output_path =f'/content/output_video({N}%).mp4'\n",
        "assert os.path.exists(video_path), f\"Файл {video_path} не найден\"\n",
        "\n",
        "# --- Открываем видео ---\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "    raise IOError(f\"Не удалось открыть видео {video_path}\")\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# --- Обрезка N% из центра видео ---\n",
        "  # процент видео (например, 2%)\n",
        "segment_frames = max(1, int(total_frames * N / 100))\n",
        "\n",
        "start_frame = (total_frames - segment_frames) // 2\n",
        "end_frame = start_frame + segment_frames\n",
        "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "\n",
        "# --- Видеозапись выходного результата ---\n",
        "out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
        "\n",
        "# --- Визуализация скелета (COCO) ---\n",
        "skeleton = [[0,1],[0,2],[1,3],[2,4],[0,5],[0,6],\n",
        "            [5,7],[7,9],[6,8],[8,10],[5,11],[6,12],\n",
        "            [11,13],[13,15],[12,14],[14,16]]\n",
        "\n",
        "predictions = {}\n",
        "saved_frames = 0\n",
        "\n",
        "# --- Старт обработки ---\n",
        "print(f\"▶️ Начинаем обработку {segment_frames} кадров из центра видео ({start_frame} → {end_frame})\")\n",
        "start_time = time.time()\n",
        "\n",
        "with tqdm(total=segment_frames, desc=f'Processing {N}% center of video') as pbar:\n",
        "    for frame_idx in range(start_frame, end_frame):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(f\"[!] Видео закончилось на кадре {frame_idx}\")\n",
        "            break\n",
        "\n",
        "        # --- Детекция людей ---\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        input_tensor = torchvision.transforms.ToTensor()(frame_rgb).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = detector([input_tensor])[0]\n",
        "\n",
        "        boxes = outputs['boxes'].cpu().numpy()\n",
        "        scores = outputs['scores'].cpu().numpy()\n",
        "        labels = outputs['labels'].cpu().numpy()\n",
        "        mask = (scores > 0.5) & (labels == 1)\n",
        "        boxes = boxes[mask]; scores = scores[mask]\n",
        "\n",
        "        # --- Трекинг ---\n",
        "        detections = []\n",
        "        for (x1,y1,x2,y2), score in zip(boxes, scores):\n",
        "            w_box, h_box = x2 - x1, y2 - y1\n",
        "            detections.append(([int(x1), int(y1), int(w_box), int(h_box)], float(score), 'person'))\n",
        "        tracks = tracker.update_tracks(detections, frame=frame)\n",
        "\n",
        "        frame_results = []\n",
        "        for track in tracks:\n",
        "            if not track.is_confirmed():\n",
        "                continue\n",
        "            track_id = track.track_id\n",
        "            l,t,r,b = track.to_ltrb(orig=True)\n",
        "            frame_results.append({'track_id': track_id, 'bbox': [l,t,r,b]})\n",
        "\n",
        "        # --- Оценка позы ---\n",
        "        for res in frame_results:\n",
        "            l,t,r,b = res['bbox']\n",
        "            pose_res = inference_topdown(pose_model, frame, bboxes=np.array([[l,t,r,b]], dtype=np.float32))\n",
        "            pred_instances = pose_res[0].pred_instances\n",
        "            if pred_instances.keypoints is not None and len(pred_instances.keypoints) > 0:\n",
        "                res['keypoints'] = pred_instances.keypoints[0]\n",
        "                res['keypoint_scores'] = pred_instances.keypoint_scores[0]\n",
        "\n",
        "        predictions[frame_idx] = frame_results\n",
        "\n",
        "        # --- Визуализация ---\n",
        "        for res in frame_results:\n",
        "            l,t,r,b = res['bbox']\n",
        "            cv2.rectangle(frame, (int(l),int(t)), (int(r),int(b)), (0,255,0), 2)\n",
        "            cv2.putText(frame, f'ID {res[\"track_id\"]}', (int(l), int(t)-10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
        "            if 'keypoints' in res:\n",
        "                kps = res['keypoints']\n",
        "                ks = res['keypoint_scores']\n",
        "                for idx, (x, y) in enumerate(kps):\n",
        "                    if ks[idx] > 0.3:\n",
        "                        cv2.circle(frame, (int(x), int(y)), 3, (0,0,255), -1)\n",
        "                for (p, q) in skeleton:\n",
        "                    if ks[p] > 0.3 and ks[q] > 0.3:\n",
        "                        pt1 = (int(kps[p][0]), int(kps[p][1]))\n",
        "                        pt2 = (int(kps[q][0]), int(kps[q][1]))\n",
        "                        cv2.line(frame, pt1, pt2, (255, 0, 0), 2)\n",
        "\n",
        "        out.write(frame)\n",
        "        saved_frames += 1\n",
        "        pbar.update(1)\n",
        "\n",
        "# --- Завершаем ---\n",
        "cap.release()\n",
        "out.release()\n",
        "end_time = time.time()\n",
        "duration = end_time - start_time\n",
        "fps_processed = saved_frames / duration if duration > 0 else 0\n",
        "\n",
        "print(f\"\\n✅ Обработка завершена: {saved_frames} кадров за {duration:.1f} сек. ({fps_processed:.2f} FPS)\")\n",
        "print(f\"📦 Выходной файл: {output_path}\")\n",
        "!ls -lh {output_path}\n"
      ],
      "metadata": {
        "id": "W-nVAhJ8BxOc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186,
          "referenced_widgets": [
            "fe9ce525717147579951bf9a2ee604c0",
            "ea7e6d3b99c14e6c8dd0d90d9c889833",
            "bdfd8be8dfb64fa6bb4488852e0349d4",
            "b5dc5f66647e48b386bd038ec3d6e770",
            "599802674ce446aca475c1e943f1dadd",
            "9c5c1a91cd31439cb9c6cb5e2ccac56f",
            "8f9e989b79ad48a397c25280e06e42cb",
            "f7df8a0b7f464286ae524ba5d820ac36",
            "1d8b941b46de4c18a5ca64a57a986760",
            "8baab977c7aa4481a657c29acfa75ba9",
            "fa649fe84d1142319bb264073a834dfb"
          ]
        },
        "outputId": "6b3fedd8-240f-4634-bfa3-b72aadf259f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ Начинаем обработку 2 кадров из центра видео (2688 → 2690)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing 0.05% center of video:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe9ce525717147579951bf9a2ee604c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Обработка завершена: 2 кадров за 2.2 сек. (0.93 FPS)\n",
            "📦 Выходной файл: /content/output_video(0.05%).mp4\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `ls -lh /content/output_video(0.05%).mp4'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Penn_Action"
      ],
      "metadata": {
        "id": "63UZSK4NlWum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Скачивание и распаковка\n",
        "import os, urllib.request, tarfile\n",
        "DATA_ROOT = '/content/Penn_Action'\n",
        "\n",
        "if not os.path.exists(os.path.join(DATA_ROOT, 'frames')):\n",
        "    print(\"⬇️ Скачиваем Penn Action...\")\n",
        "    urllib.request.urlretrieve(\n",
        "        'https://www.cis.upenn.edu/~kostas/Penn_Action.tar.gz',\n",
        "        '/content/Penn_Action.tar.gz'\n",
        "    )\n",
        "    print(\"🗂️ Распаковываем...\")\n",
        "    with tarfile.open('/content/Penn_Action.tar.gz', 'r:gz') as f:\n",
        "        f.extractall('/content/')\n",
        "    os.rename('/content/Penn_Action', DATA_ROOT)\n",
        "print(\"✅ Датасет готов:\", os.listdir(DATA_ROOT))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaxF7dAAqxVO",
        "outputId": "df3229ff-bbfb-4ef3-d90c-1a991065aaa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬇️ Скачиваем Penn Action...\n",
            "🗂️ Распаковываем...\n",
            "✅ Датасет готов: ['frames', 'labels', 'tools', 'README']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io as sio\n",
        "mat = sio.loadmat('/content/Penn_Action/labels/0001.mat')\n",
        "print(mat['x'].shape, mat['y'].shape, mat['visibility'].shape)  # (nframes, 13)\n",
        "print([\"head\",\"l_sh\",\"r_sh\",\"l_el\",\"r_el\",\"l_wr\",\"r_wr\",\"l_hi\",\"r_hi\",\"l_kn\",\"r_kn\",\"l_an\",\"r_an\"])\n"
      ],
      "metadata": {
        "id": "DQJkBBmYXlJV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a320388e-7953-4f11-c614-b5938d3f4b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(151, 13) (151, 13) (151, 13)\n",
            "['head', 'l_sh', 'r_sh', 'l_el', 'r_el', 'l_wr', 'r_wr', 'l_hi', 'r_hi', 'l_kn', 'r_kn', 'l_an', 'r_an']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, cv2, glob, numpy as np, torch, torchvision\n",
        "from tqdm.notebook import tqdm\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from mmpose.apis import init_model, inference_topdown\n",
        "\n",
        "# === Параметры ===\n",
        "DATA_ROOT = '/content/Penn_Action'\n",
        "FRAMES_DIR = os.path.join(DATA_ROOT, 'frames')\n",
        "OUTPUT_VIDEO = '/content/output_annotated_unlabeled_ID.mp4'\n",
        "V = 1  # количество людей для отображения\n",
        "\n",
        "# Инициализация моделей и трекера\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "det = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT').to(device)\n",
        "det.eval()\n",
        "tracker = DeepSort(max_age=5, n_init=1)\n",
        "\n",
        "pose_cfg = 'mmpose/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-256x192.py'\n",
        "pose_ckpt = 'hrnet_w48_coco_256x192.pth'\n",
        "if not os.path.exists(pose_ckpt):\n",
        "    !wget -q https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth -O {pose_ckpt}\n",
        "pose_model = init_model(pose_cfg, pose_ckpt, device=device)\n",
        "\n",
        "# Выбор первого видео с ≥20 кадров\n",
        "vids = sorted(os.listdir(FRAMES_DIR))\n",
        "for vid in vids:\n",
        "    files = sorted(glob.glob(os.path.join(FRAMES_DIR, vid, '*.jpg')))\n",
        "    if len(files) >= 20:\n",
        "        pick_vid = vid\n",
        "        break\n",
        "\n",
        "frames = sorted(glob.glob(os.path.join(FRAMES_DIR, pick_vid, '*.jpg')))\n",
        "total = len(frames)\n",
        "seg =150\n",
        "start = max(0, (total - seg)//2)\n",
        "selected = frames[start:start+seg]\n",
        "\n",
        "# Настройка видео write\n",
        "sample = cv2.imread(selected[0])\n",
        "h, w = sample.shape[:2]\n",
        "out = cv2.VideoWriter(OUTPUT_VIDEO, cv2.VideoWriter_fourcc(*'mp4v'), 15, (w,h))\n",
        "\n",
        "# Скелет COCO\n",
        "skeleton = [[0,1],[0,2],[1,3],[2,4],[0,5],[0,6],\n",
        "            [5,7],[7,9],[6,8],[8,10],[5,11],[6,12],\n",
        "            [11,13],[13,15],[12,14],[14,16]]\n",
        "\n",
        "print(f\"▶️ Обрабатываем '{pick_vid}', кадры {start}-{start+seg-1}\")\n",
        "\n",
        "for fp in tqdm(selected):\n",
        "    frame = cv2.imread(fp)\n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    t = torchvision.transforms.ToTensor()(rgb).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out_det = det([t])[0]\n",
        "\n",
        "    mask = (out_det['scores']>0.5)&(out_det['labels']==1)\n",
        "    boxes = out_det['boxes'][mask].cpu().numpy()\n",
        "    scores = out_det['scores'][mask].cpu().numpy()\n",
        "    dets = [([int(b[0]),int(b[1]),int(b[2]-b[0]),int(b[3]-b[1])], s, 'person')\n",
        "            for b,s in zip(boxes, scores)]\n",
        "    tracks = tracker.update_tracks(dets, frame=frame)\n",
        "\n",
        "    # Собираем подтверждённые треки и сортируем по track_id\n",
        "    confirmed = [tr for tr in tracks if tr.is_confirmed()]\n",
        "    confirmed.sort(key=lambda tr: tr.track_id)\n",
        "\n",
        "    # Выбираем первые V по ID\n",
        "    for tr in confirmed[:V]:\n",
        "        tid = tr.track_id\n",
        "        l,t_,u,v = map(int, tr.to_ltrb(orig=True))\n",
        "        cv2.rectangle(frame, (l,t_), (u,v), (0,255,0), 2)\n",
        "        cv2.putText(frame, f'ID {tid}', (l, t_-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
        "\n",
        "        pose = inference_topdown(pose_model, frame, np.array([[l,t_,u,v]], dtype=np.float32))[0]\n",
        "        if pose.pred_instances.keypoints is not None:\n",
        "            kps = pose.pred_instances.keypoints[0]\n",
        "            ksc = pose.pred_instances.keypoint_scores[0]\n",
        "            for i,(x,y) in enumerate(kps):\n",
        "                if ksc[i] > 0.3:\n",
        "                    cv2.circle(frame, (int(x),int(y)), 3, (0,0,255), -1)\n",
        "            for p,q in skeleton:\n",
        "                if ksc[p]>0.3 and ksc[q]>0.3:\n",
        "                    pt1 = tuple(kps[p].astype(int))\n",
        "                    pt2 = tuple(kps[q].astype(int))\n",
        "                    cv2.line(frame, pt1, pt2, (255,0,0), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()\n",
        "print(f\"✅ Сохранено: {OUTPUT_VIDEO}\")\n"
      ],
      "metadata": {
        "id": "jbDUgy1SDGWe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160,
          "referenced_widgets": [
            "4b5fec85ed544088aea10f0690f9f53e",
            "c8ea9d33778340f5983cbe95086cdf7b",
            "6c3abf11074d4972a4b6b6f501728f38",
            "f8e8c2cd3b16484fabaed06b237f5859",
            "a53af95a867e4fec8dc06145175079f8",
            "d1f66efd65a442aa85ad8b8b6c7259a5",
            "8bd47e9049f3451e8af0cfe7d49d5f84",
            "dc8415c571c54d65a01eb30e50481ae5",
            "18994428e34644debd16c9779c51775a",
            "8a0e1931ac254a8ca6f7731fff53df21",
            "2e769ee6b39249d1af2f7f99a920aab0"
          ]
        },
        "outputId": "04e1611a-95da-4d97-df47-b886361b3a94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loads checkpoint by local backend from path: hrnet_w48_coco_256x192.pth\n",
            "▶️ Обрабатываем '0001', кадры 0-149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mmpose/mmpose/datasets/datasets/utils.py:102: UserWarning: The metainfo config file \"configs/_base_/datasets/coco.py\" does not exist. A matched config file \"/content/mmpose/mmpose/.mim/configs/_base_/datasets/coco.py\" will be used instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/150 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b5fec85ed544088aea10f0690f9f53e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Сохранено: /content/output_annotated_unlabeled_ID.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, cv2, glob, numpy as np, torch, torchvision, scipy.io\n",
        "from tqdm import tqdm\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from mmpose.apis import init_model, inference_topdown\n",
        "\n",
        "# --- Параметры ---\n",
        "DATA_ROOT = '/content/Penn_Action'\n",
        "FRAMES_DIR = os.path.join(DATA_ROOT, 'frames')\n",
        "LABELS_DIR = os.path.join(DATA_ROOT, 'labels')\n",
        "POSE_CFG = 'mmpose/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-256x192.py'\n",
        "POSE_CKPT = 'hrnet_w48_coco_256x192.pth'\n",
        "TARGET_FRAMES = 100  # нужно собрать минимум столько кадров\n",
        "MAX_FRAMES_PER_VIDEO = 20\n",
        "\n",
        "# --- Инициализация моделей ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "detector = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT').to(device)\n",
        "detector.eval()\n",
        "tracker = DeepSort(max_age=5, n_init=1)\n",
        "if not os.path.exists(POSE_CKPT):\n",
        "    os.system(f'wget -q https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth -O {POSE_CKPT}')\n",
        "pose_model = init_model(POSE_CFG, POSE_CKPT, device=device)\n",
        "\n",
        "# --- Сбор видео с наибольшей длиной анотаций ---\n",
        "video_lengths = []\n",
        "for vid in os.listdir(FRAMES_DIR):\n",
        "    files = glob.glob(f'{FRAMES_DIR}/{vid}/*.jpg')\n",
        "    if os.path.exists(f'{LABELS_DIR}/{vid}.mat'):\n",
        "        mat = scipy.io.loadmat(f'{LABELS_DIR}/{vid}.mat')\n",
        "        nframes = int(mat['nframes'][0][0])\n",
        "        video_lengths.append((vid, nframes))\n",
        "\n",
        "video_lengths.sort(key=lambda x: -x[1])  # от большего к меньшему\n",
        "\n",
        "frames_list, collected, processed_videos = [], 0, []\n",
        "\n",
        "for vid, vlen in video_lengths:\n",
        "    if collected >= TARGET_FRAMES:\n",
        "        break\n",
        "\n",
        "    frame_files = sorted(glob.glob(f'{FRAMES_DIR}/{vid}/*.jpg'))\n",
        "    mat = scipy.io.loadmat(f'{LABELS_DIR}/{vid}.mat')\n",
        "    available = min(MAX_FRAMES_PER_VIDEO, vlen, len(frame_files), TARGET_FRAMES - collected)\n",
        "\n",
        "    if available < 5:\n",
        "        continue\n",
        "\n",
        "    for idx in range(available):\n",
        "        frames_list.append((frame_files[idx], mat, idx, vid))\n",
        "\n",
        "    collected += available\n",
        "    processed_videos.append((vid, available))\n",
        "\n",
        "print(f\"Кадров для обработки: {len(frames_list)}\")\n",
        "print(\"Обработанные видео:\")\n",
        "for vid, count in processed_videos:\n",
        "    print(f\" - {vid}: {count} кадров\")\n",
        "\n",
        "# --- Метрики ---\n",
        "all_pred_kps, all_true_kps, all_visible = [], [], []\n",
        "all_pred_bboxes, all_true_bboxes = [], []\n",
        "\n",
        "# --- Скелет COCO ---\n",
        "skeleton = [[0,1],[0,2],[1,3],[2,4],[0,5],[0,6],[5,7],[7,9],[6,8],[8,10],[5,11],[6,12],[11,13],[13,15],[12,14],[14,16]]\n",
        "\n",
        "# --- Обработка кадров ---\n",
        "for path, mat, idx, vid in tqdm(frames_list):\n",
        "    frame = cv2.imread(path)\n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    t = torchvision.transforms.ToTensor()(rgb).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out_det = detector([t])[0]\n",
        "\n",
        "    mask = (out_det['scores'] > 0.5) & (out_det['labels'] == 1)\n",
        "    boxes = out_det['boxes'][mask].cpu().numpy()\n",
        "    scores = out_det['scores'][mask].cpu().numpy()\n",
        "    dets = [([int(b[0]), int(b[1]), int(b[2]-b[0]), int(b[3]-b[1])], s, 'person') for b, s in zip(boxes, scores)]\n",
        "    tracks = tracker.update_tracks(dets, frame=frame)\n",
        "\n",
        "    confirmed = [tr for tr in tracks if tr.is_confirmed()]\n",
        "    confirmed.sort(key=lambda tr: tr.track_id)\n",
        "\n",
        "    if len(confirmed) == 0:\n",
        "        continue\n",
        "\n",
        "    tr = confirmed[0]  # используем только первого человека\n",
        "    l, t_, u, v = map(int, tr.to_ltrb(orig=True))\n",
        "    bbox_pred = [l, t_, u, v]\n",
        "    out_pose = inference_topdown(pose_model, frame, np.array([[l, t_, u, v]], dtype=np.float32))[0]\n",
        "\n",
        "    if out_pose.pred_instances.keypoints is None:\n",
        "        continue\n",
        "\n",
        "    kps_pred = out_pose.pred_instances.keypoints[0]\n",
        "    ksc = out_pose.pred_instances.keypoint_scores[0]\n",
        "\n",
        "    # GT keypoints Penn (13 → COCO 17)\n",
        "    x_gt, y_gt, vis_gt = mat['x'][idx], mat['y'][idx], mat['visibility'][idx].astype(bool)\n",
        "    true_kps_coco, vis_coco = np.full((17, 2), np.nan), np.zeros(17, dtype=bool)\n",
        "    map_penn_to_coco = {0:0, 1:5, 2:6, 3:7, 4:8, 5:9, 6:10, 7:11, 8:12, 9:13, 10:14, 11:15, 12:16}\n",
        "\n",
        "    for p_idx, coco_idx in map_penn_to_coco.items():\n",
        "        true_kps_coco[coco_idx] = [x_gt[p_idx], y_gt[p_idx]]\n",
        "        vis_coco[coco_idx] = vis_gt[p_idx]\n",
        "\n",
        "    all_pred_kps.append(kps_pred)\n",
        "    all_true_kps.append(true_kps_coco)\n",
        "    all_visible.append(vis_coco)\n",
        "\n",
        "    bbox_gt = mat['bbox'][idx]\n",
        "    all_true_bboxes.append(bbox_gt)\n",
        "    all_pred_bboxes.append(bbox_pred)\n",
        "\n",
        "# --- Расчёт метрик ---\n",
        "visible = np.stack(all_visible)\n",
        "true_kps, pred_kps = np.stack(all_true_kps), np.stack(all_pred_kps)\n",
        "valid = visible & ~np.isnan(true_kps[:, :, 0])\n",
        "errors = np.linalg.norm(pred_kps - true_kps, axis=2)\n",
        "mae, mse = np.mean(errors[valid]), np.mean(errors[valid]**2)\n",
        "\n",
        "def iou(boxA, boxB):\n",
        "    xA, yA = max(boxA[0], boxB[0]), max(boxA[1], boxB[1])\n",
        "    xB, yB = min(boxA[2], boxB[2]), min(boxA[3], boxB[3])\n",
        "    inter = max(0, xB - xA) * max(0, yB - yA)\n",
        "    areaA = max(0, boxA[2] - boxA[0]) * max(0, boxA[3] - boxA[1])\n",
        "    areaB = max(0, boxB[2] - boxB[0]) * max(0, boxB[3] - boxB[1])\n",
        "    union = areaA + areaB - inter\n",
        "    return inter / union if union > 0 else 0\n",
        "\n",
        "iou_scores = [iou(pred, true) for pred, true in zip(all_pred_bboxes, all_true_bboxes)]\n",
        "\n",
        "print(\"\\n📊 Метрики:\")\n",
        "print(f\"MAE по keypoints: {mae:.2f} пикселя\")\n",
        "print(f\"MSE по keypoints: {mse:.2f} пикселя²\")\n",
        "print(f\"Средний IOU по bbox: {np.mean(iou_scores):.3f}\")\n"
      ],
      "metadata": {
        "id": "_MyI5GsLG_We",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2c3eef-a1ef-46aa-8d74-0265934d00d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loads checkpoint by local backend from path: hrnet_w48_coco_256x192.pth\n",
            "Кадров для обработки: 100\n",
            "Обработанные видео:\n",
            " - 0758: 20 кадров\n",
            " - 0748: 20 кадров\n",
            " - 0623: 20 кадров\n",
            " - 0731: 20 кадров\n",
            " - 0755: 20 кадров\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:23<00:00,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Метрики:\n",
            "MAE по keypoints: 56.94 пикселя\n",
            "MSE по keypoints: 4617.94 пикселя²\n",
            "Средний IOU по bbox: 0.714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import scipy.io\n",
        "from tqdm import tqdm\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from mmpose.apis import init_model, inference_topdown\n",
        "\n",
        "# --- Параметры ---\n",
        "DATA_ROOT = '/content/Penn_Action'\n",
        "FRAMES_DIR = os.path.join(DATA_ROOT, 'frames')\n",
        "LABELS_DIR = os.path.join(DATA_ROOT, 'labels')\n",
        "POSE_CFG = 'mmpose/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-256x192.py'\n",
        "POSE_CKPT = 'hrnet_w48_coco_256x192.pth'\n",
        "TARGET_FRAMES = 1000  # нужно собрать минимум столько кадров\n",
        "MAX_FRAMES_PER_VIDEO = 10\n",
        "\n",
        "# --- Инициализация моделей ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "detector = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT').to(device)\n",
        "detector.eval()\n",
        "tracker = DeepSort(max_age=5, n_init=1)\n",
        "if not os.path.exists(POSE_CKPT):\n",
        "    os.system(f'wget -q https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth -O {POSE_CKPT}')\n",
        "pose_model = init_model(POSE_CFG, POSE_CKPT, device=device)\n",
        "\n",
        "# --- Сбор видео с наибольшей длиной анотаций ---\n",
        "video_lengths = []\n",
        "for vid in os.listdir(FRAMES_DIR):\n",
        "    files = glob.glob(f'{FRAMES_DIR}/{vid}/*.jpg')\n",
        "    if os.path.exists(f'{LABELS_DIR}/{vid}.mat'):\n",
        "        mat = scipy.io.loadmat(f'{LABELS_DIR}/{vid}.mat')\n",
        "        nframes = int(mat['nframes'][0][0])\n",
        "        video_lengths.append((vid, nframes))\n",
        "\n",
        "video_lengths.sort(key=lambda x: -x[1])  # от большего к меньшему\n",
        "\n",
        "frames_list, collected, processed_videos = [], 0, []\n",
        "\n",
        "for vid, vlen in video_lengths:\n",
        "    if collected >= TARGET_FRAMES:\n",
        "        break\n",
        "\n",
        "    frame_files = sorted(glob.glob(f'{FRAMES_DIR}/{vid}/*.jpg'))\n",
        "    mat = scipy.io.loadmat(f'{LABELS_DIR}/{vid}.mat')\n",
        "    available = min(MAX_FRAMES_PER_VIDEO, vlen, len(frame_files), TARGET_FRAMES - collected)\n",
        "\n",
        "    if available < 5:\n",
        "        continue\n",
        "\n",
        "    for idx in range(available):\n",
        "        frames_list.append((frame_files[idx], mat, idx, vid))\n",
        "\n",
        "    collected += available\n",
        "    processed_videos.append((vid, available))\n",
        "\n",
        "print(f\"Кадров для обработки: {len(frames_list)}\")\n",
        "print(\"Обработанные видео:\")\n",
        "for vid, count in processed_videos:\n",
        "    print(f\" - {vid}: {count} кадров\")\n",
        "\n",
        "# --- Метрики ---\n",
        "all_pred_kps, all_true_kps, all_visible = [], [], []\n",
        "all_pred_bboxes, all_true_bboxes = [], []\n",
        "\n",
        "# --- Скелет COCO ---\n",
        "skeleton = [[0,1],[0,2],[1,3],[2,4],[0,5],[0,6],[5,7],[7,9],[6,8],[8,10],[5,11],[6,12],[11,13],[13,15],[12,14],[14,16]]\n",
        "\n",
        "# --- Функция подсчёта IOU ---\n",
        "def iou(boxA, boxB):\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "    interW = max(0, xB - xA)\n",
        "    interH = max(0, yB - yA)\n",
        "    interArea = interW * interH\n",
        "    boxAArea = max(0, boxA[2] - boxA[0]) * max(0, boxA[3] - boxA[1])\n",
        "    boxBArea = max(0, boxB[2] - boxB[0]) * max(0, boxB[3] - boxB[1])\n",
        "    union = boxAArea + boxBArea - interArea\n",
        "    if union == 0:\n",
        "        return 0\n",
        "    return interArea / union\n",
        "\n",
        "# --- Обработка кадров ---\n",
        "for path, mat, idx, vid in tqdm(frames_list):\n",
        "    frame = cv2.imread(path)\n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    t = torchvision.transforms.ToTensor()(rgb).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out_det = detector([t])[0]\n",
        "\n",
        "    mask = (out_det['scores'] > 0.5) & (out_det['labels'] == 1)\n",
        "    boxes = out_det['boxes'][mask].cpu().numpy()\n",
        "    scores = out_det['scores'][mask].cpu().numpy()\n",
        "    dets = [([int(b[0]), int(b[1]), int(b[2]-b[0]), int(b[3]-b[1])], s, 'person') for b, s in zip(boxes, scores)]\n",
        "    tracks = tracker.update_tracks(dets, frame=frame)\n",
        "\n",
        "    confirmed = [tr for tr in tracks if tr.is_confirmed()]\n",
        "    confirmed.sort(key=lambda tr: tr.track_id)\n",
        "\n",
        "    if len(confirmed) == 0:\n",
        "        continue\n",
        "\n",
        "    tr = confirmed[0]  # используем только первого человека\n",
        "    l, t_, u, v = map(int, tr.to_ltrb(orig=True))\n",
        "    bbox_pred = [l, t_, u, v]\n",
        "\n",
        "    out_pose = inference_topdown(pose_model, frame, np.array([[l, t_, u, v]], dtype=np.float32))[0]\n",
        "\n",
        "    if out_pose.pred_instances.keypoints is None:\n",
        "        continue\n",
        "\n",
        "    kps_pred = out_pose.pred_instances.keypoints[0]\n",
        "    ksc = out_pose.pred_instances.keypoint_scores[0]\n",
        "\n",
        "    # GT keypoints Penn (13 → COCO 17)\n",
        "    x_gt, y_gt, vis_gt = mat['x'][idx], mat['y'][idx], mat['visibility'][idx].astype(bool)\n",
        "    true_kps_coco = np.full((17, 2), np.nan)\n",
        "    vis_coco = np.zeros(17, dtype=bool)\n",
        "    map_penn_to_coco = {0:0, 1:5, 2:6, 3:7, 4:8, 5:9, 6:10, 7:11, 8:12, 9:13, 10:14, 11:15, 12:16}\n",
        "\n",
        "    for p_idx, coco_idx in map_penn_to_coco.items():\n",
        "        true_kps_coco[coco_idx] = [x_gt[p_idx], y_gt[p_idx]]\n",
        "        vis_coco[coco_idx] = vis_gt[p_idx]\n",
        "\n",
        "    all_pred_kps.append(kps_pred)\n",
        "    all_true_kps.append(true_kps_coco)\n",
        "    all_visible.append(vis_coco)\n",
        "\n",
        "    bbox_gt = mat['bbox'][idx]\n",
        "    all_true_bboxes.append(bbox_gt)\n",
        "    all_pred_bboxes.append(bbox_pred)\n",
        "\n",
        "# --- Расчёт метрик ---\n",
        "visible = np.stack(all_visible)\n",
        "true_kps = np.stack(all_true_kps)\n",
        "pred_kps = np.stack(all_pred_kps)\n",
        "valid = visible & ~np.isnan(true_kps[:, :, 0])\n",
        "errors = np.linalg.norm(pred_kps - true_kps, axis=2)\n",
        "mae = np.mean(errors[valid])\n",
        "mse = np.mean(errors[valid]**2)\n",
        "\n",
        "iou_scores = [iou(pred, true) for pred, true in zip(all_pred_bboxes, all_true_bboxes)]\n",
        "mean_iou = np.mean(iou_scores)\n",
        "\n",
        "print(\"\\n📊 Метрики в формате Penn:\")\n",
        "print(f\"MAE по keypoints: {mae:.2f} пикселя\")\n",
        "print(f\"MSE по keypoints: {mse:.2f} пикселя²\")\n",
        "print(f\"Средний IOU по bbox: {mean_iou:.3f}\")\n"
      ],
      "metadata": {
        "id": "cUb6ggCpNnRC",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4b9e32-e93c-46f1-96ae-f39d129d233e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loads checkpoint by local backend from path: hrnet_w48_coco_256x192.pth\n",
            "Кадров для обработки: 1000\n",
            "Обработанные видео:\n",
            " - 0758: 10 кадров\n",
            " - 0748: 10 кадров\n",
            " - 0623: 10 кадров\n",
            " - 0731: 10 кадров\n",
            " - 0755: 10 кадров\n",
            " - 0736: 10 кадров\n",
            " - 0750: 10 кадров\n",
            " - 0723: 10 кадров\n",
            " - 0761: 10 кадров\n",
            " - 0746: 10 кадров\n",
            " - 0737: 10 кадров\n",
            " - 0762: 10 кадров\n",
            " - 0719: 10 кадров\n",
            " - 0726: 10 кадров\n",
            " - 0753: 10 кадров\n",
            " - 0779: 10 кадров\n",
            " - 0754: 10 кадров\n",
            " - 0715: 10 кадров\n",
            " - 0735: 10 кадров\n",
            " - 0787: 10 кадров\n",
            " - 0744: 10 кадров\n",
            " - 0781: 10 кадров\n",
            " - 0776: 10 кадров\n",
            " - 0752: 10 кадров\n",
            " - 0740: 10 кадров\n",
            " - 0774: 10 кадров\n",
            " - 0767: 10 кадров\n",
            " - 0702: 10 кадров\n",
            " - 0785: 10 кадров\n",
            " - 0778: 10 кадров\n",
            " - 0727: 10 кадров\n",
            " - 0769: 10 кадров\n",
            " - 0741: 10 кадров\n",
            " - 0716: 10 кадров\n",
            " - 1173: 10 кадров\n",
            " - 0770: 10 кадров\n",
            " - 0768: 10 кадров\n",
            " - 0734: 10 кадров\n",
            " - 0708: 10 кадров\n",
            " - 0751: 10 кадров\n",
            " - 0728: 10 кадров\n",
            " - 0718: 10 кадров\n",
            " - 0738: 10 кадров\n",
            " - 0773: 10 кадров\n",
            " - 0763: 10 кадров\n",
            " - 0729: 10 кадров\n",
            " - 0749: 10 кадров\n",
            " - 0714: 10 кадров\n",
            " - 0713: 10 кадров\n",
            " - 0732: 10 кадров\n",
            " - 0772: 10 кадров\n",
            " - 0743: 10 кадров\n",
            " - 0780: 10 кадров\n",
            " - 0784: 10 кадров\n",
            " - 0782: 10 кадров\n",
            " - 0786: 10 кадров\n",
            " - 0775: 10 кадров\n",
            " - 0777: 10 кадров\n",
            " - 0032: 10 кадров\n",
            " - 0760: 10 кадров\n",
            " - 1645: 10 кадров\n",
            " - 0739: 10 кадров\n",
            " - 0701: 10 кадров\n",
            " - 0757: 10 кадров\n",
            " - 1608: 10 кадров\n",
            " - 0706: 10 кадров\n",
            " - 0473: 10 кадров\n",
            " - 0766: 10 кадров\n",
            " - 0720: 10 кадров\n",
            " - 0724: 10 кадров\n",
            " - 0764: 10 кадров\n",
            " - 0783: 10 кадров\n",
            " - 0759: 10 кадров\n",
            " - 0717: 10 кадров\n",
            " - 0733: 10 кадров\n",
            " - 1602: 10 кадров\n",
            " - 0426: 10 кадров\n",
            " - 1237: 10 кадров\n",
            " - 1172: 10 кадров\n",
            " - 0771: 10 кадров\n",
            " - 1566: 10 кадров\n",
            " - 0765: 10 кадров\n",
            " - 1467: 10 кадров\n",
            " - 1305: 10 кадров\n",
            " - 1218: 10 кадров\n",
            " - 1858: 10 кадров\n",
            " - 0756: 10 кадров\n",
            " - 0393: 10 кадров\n",
            " - 0396: 10 кадров\n",
            " - 1754: 10 кадров\n",
            " - 0704: 10 кадров\n",
            " - 0478: 10 кадров\n",
            " - 1334: 10 кадров\n",
            " - 0415: 10 кадров\n",
            " - 1285: 10 кадров\n",
            " - 1599: 10 кадров\n",
            " - 1185: 10 кадров\n",
            " - 1725: 10 кадров\n",
            " - 1808: 10 кадров\n",
            " - 0392: 10 кадров\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [03:58<00:00,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Метрики в формате Penn:\n",
            "MAE по keypoints: 65.45 пикселя\n",
            "MSE по keypoints: 8267.59 пикселя²\n",
            "Средний IOU по bbox: 0.530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "video_id = '0001'\n",
        "labels_dir = '/content/Penn_Action/labels'\n",
        "label_path = os.path.join(labels_dir, f'{video_id}.mat')\n",
        "\n",
        "mat = scipy.io.loadmat(label_path)\n",
        "# Проверяем содержимое\n",
        "print(mat.keys())\n"
      ],
      "metadata": {
        "id": "yEmnQ1NRBUXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "564a061e-3447-462e-f8ba-f712124bcde2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['__header__', '__version__', '__globals__', 'action', 'pose', 'x', 'y', 'visibility', 'train', 'bbox', 'dimensions', 'nframes'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "\n",
        "# Путь к датасету\n",
        "DATASET_DIR = '/content/Penn_Action'\n",
        "video_id = '0010'\n",
        "\n",
        "frames_dir = os.path.join(DATASET_DIR, 'frames', video_id)\n",
        "label_path = os.path.join(DATASET_DIR, 'labels', f'{video_id}.mat')\n",
        "\n",
        "# Загружаем аннотацию\n",
        "mat = scipy.io.loadmat(label_path)\n",
        "\n",
        "# Извлекаем поля напрямую\n",
        "xs = mat['x']            # shape: (n_frames, 13)\n",
        "ys = mat['y']\n",
        "vis = mat['visibility']  # shape: (n_frames, 13)\n",
        "bboxes = mat['bbox']     # shape: (n_frames, 4)\n",
        "\n",
        "nframes = int(mat['nframes'][0][0])\n",
        "\n",
        "# Получим список кадров\n",
        "frame_files = sorted(os.listdir(frames_dir))\n",
        "frame_paths = [os.path.join(frames_dir, f) for f in frame_files if f.endswith('.jpg')]\n",
        "\n",
        "# Настройка видео-сохранения\n",
        "sample_frame = cv2.imread(frame_paths[0])\n",
        "height, width = sample_frame.shape[:2]\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out_path = f'/content/penn_action_annotated_{video_id}.mp4'\n",
        "out = cv2.VideoWriter(out_path, fourcc, 15, (width, height))\n",
        "\n",
        "# Цвета и связи (скелет)\n",
        "color = (0, 255, 0)\n",
        "joint_pairs = [\n",
        "    (0,1), (1,3), (0,2), (2,4),  # голова → плечи → локти\n",
        "    (1,5), (2,6),                # плечи → бедра\n",
        "    (5,7), (6,8),                # бедра → колени\n",
        "    (7,9), (8,10),              # колени → лодыжки\n",
        "    (1,2)                        # между плечами\n",
        "]\n",
        "\n",
        "# Визуализация\n",
        "for i in range(min(nframes, len(frame_paths))):\n",
        "    frame = cv2.imread(frame_paths[i])\n",
        "    if frame is None:\n",
        "        continue\n",
        "\n",
        "    # Нарисуем ключевые точки\n",
        "    for j in range(13):\n",
        "        if vis[i, j]:\n",
        "            x, y = int(xs[i, j]), int(ys[i, j])\n",
        "            cv2.circle(frame, (x, y), 4, color, -1)\n",
        "\n",
        "    # Нарисуем соединения\n",
        "    for j1, j2 in joint_pairs:\n",
        "        if vis[i, j1] and vis[i, j2]:\n",
        "            pt1 = (int(xs[i, j1]), int(ys[i, j1]))\n",
        "            pt2 = (int(xs[i, j2]), int(ys[i, j2]))\n",
        "            cv2.line(frame, pt1, pt2, (255, 0, 0), 2)\n",
        "\n",
        "    # Нарисуем bbox\n",
        "    x1, y1, x2, y2 = map(int, bboxes[i])\n",
        "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()\n",
        "print(f\"✅ Сохранено видео с аннотацией: {out_path}\")\n"
      ],
      "metadata": {
        "id": "t4CurXnqA3e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad2c7a67-0fdc-4aff-d4ef-a13ac01b5f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Сохранено видео с аннотацией: /content/penn_action_annotated_0010.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RYDb7rxSlcxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Сравнение yolo11n-pose и  Faster R-CNN + HRNet"
      ],
      "metadata": {
        "id": "DaMILsTpldDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torchvision\n",
        "from mmpose.apis import init_model, inference_topdown\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Устройство для вычислений\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Параметры\n",
        "video_path = '/content/input_video.mp4'\n",
        "output_dir = '/content/output'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "yolo_output_path = os.path.join(output_dir, 'output_yolo.mp4')\n",
        "second_output_path = os.path.join(output_dir, 'output_second.mp4')\n",
        "\n",
        "# Создание выходных видео\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "out_yolo = cv2.VideoWriter(yolo_output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
        "out_second = cv2.VideoWriter(second_output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
        "\n",
        "POSE_CFG = 'mmpose/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-256x192.py'\n",
        "POSE_CKPT = 'hrnet_w48_coco_256x192.pth'\n",
        "\n",
        "# Загрузка модели YOLO\n",
        "yolo_model = YOLO(\"yolo11n-pose.pt\")\n",
        "\n",
        "# Инициализация моделей\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "detector = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT').to(device)\n",
        "detector.eval()\n",
        "tracker = DeepSort(max_age=25, n_init=3)\n",
        "\n",
        "# Загрузка модели pose\n",
        "if not os.path.exists(POSE_CKPT):\n",
        "    os.system(f'wget -q https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth -O {POSE_CKPT}')\n",
        "pose_model = init_model(POSE_CFG, POSE_CKPT, device=device)\n",
        "\n",
        "# Скелет для визуализации\n",
        "skeleton = [[0,1],[0,2],[1,3],[2,4],[0,5],[0,6],\n",
        "            [5,7],[7,9],[6,8],[8,10],[5,11],[6,12],\n",
        "            [11,13],[13,15],[12,14],[14,16]]\n",
        "\n",
        "# Функция для вычисления IOU между двумя боксами\n",
        "def calculate_iou(box1, box2):\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    union = area1 + area2 - intersection\n",
        "    return intersection / union if union > 0 else 0\n",
        "\n",
        "# Открытие видео\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Определение сегмента: 5% кадров из центра\n",
        "N = 20  # процент\n",
        "segment_frames = max(1, int(total_frames * N / 100))\n",
        "start_frame = (total_frames - segment_frames) // 2\n",
        "end_frame = start_frame + segment_frames\n",
        "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "\n",
        "# Списки для хранения метрик\n",
        "iou_list = []\n",
        "mae_list = []\n",
        "mse_list = []\n",
        "\n",
        "# Для отслеживания времени и скорости обработки\n",
        "yolo_times = []\n",
        "second_model_times = []\n",
        "\n",
        "# Обработка каждого кадра\n",
        "print(f\"▶️ Обработка видео: {os.path.basename(video_path)}, кадры {start_frame}-{end_frame-1}\")\n",
        "# Время обработки каждого кадра\n",
        "for _ in tqdm(range(segment_frames)):  # Упрощенный прогресс-бар\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Время обработки кадра для YOLO\n",
        "    start_time = time.time()\n",
        "    # Обработка моделью YOLO (считается \"истиной\")\n",
        "    yolo_results = yolo_model.track(frame, persist=True, tracker=\"bytetrack.yaml\")\n",
        "    yolo_boxes = yolo_results[0].boxes.xyxy.cpu().numpy()\n",
        "    yolo_keypoints = yolo_results[0].keypoints.xy.cpu().numpy()\n",
        "    yolo_time = time.time() - start_time\n",
        "    yolo_times.append(yolo_time)\n",
        "\n",
        "    # Время обработки кадра для второй модели (Faster R-CNN + HRNet)\n",
        "    start_time = time.time()\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    input_tensor = torchvision.transforms.ToTensor()(frame_rgb).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = detector([input_tensor])[0]\n",
        "    boxes = outputs['boxes'].cpu().numpy()\n",
        "    scores = outputs['scores'].cpu().numpy()\n",
        "    labels = outputs['labels'].cpu().numpy()\n",
        "    mask = (scores > 0.5) & (labels == 1)  # Фильтр по уверенности и классу \"человек\"\n",
        "    boxes = boxes[mask]\n",
        "\n",
        "    detections = []\n",
        "    for (x1, y1, x2, y2) in boxes:\n",
        "        w_box, h_box = x2 - x1, y2 - y1\n",
        "        detections.append(([int(x1), int(y1), int(w_box), int(h_box)], 1.0, 'person'))\n",
        "\n",
        "    tracks = tracker.update_tracks(detections, frame=frame)\n",
        "    second_results = []\n",
        "    for track in tracks:\n",
        "        if not track.is_confirmed():\n",
        "            continue\n",
        "        track_id = track.track_id\n",
        "        l, t, r, b = track.to_ltrb(orig=True)\n",
        "        second_results.append({'track_id': track_id, 'bbox': [l, t, r, b]})\n",
        "\n",
        "    for res in second_results:\n",
        "        l, t, r, b = res['bbox']\n",
        "        pose_res = inference_topdown(pose_model, frame, bboxes=np.array([[l, t, r, b]], dtype=np.float32))\n",
        "        pred_instances = pose_res[0].pred_instances\n",
        "        if pred_instances.keypoints is not None and len(pred_instances.keypoints) > 0:\n",
        "            res['keypoints'] = pred_instances.keypoints[0]\n",
        "\n",
        "    second_model_time = time.time() - start_time\n",
        "    second_model_times.append(second_model_time)\n",
        "\n",
        "    # Сопоставление детекций YOLO и второй модели\n",
        "    for yolo_box, yolo_kp in zip(yolo_boxes, yolo_keypoints):\n",
        "        max_iou = 0\n",
        "        matched_second_res = None\n",
        "        for second_res in second_results:\n",
        "            second_box = second_res['bbox']\n",
        "            iou = calculate_iou(yolo_box, second_box)\n",
        "            if iou > max_iou:\n",
        "                max_iou = iou\n",
        "                matched_second_res = second_res\n",
        "\n",
        "        if max_iou > 0.5 and 'keypoints' in matched_second_res:  # Порог IOU\n",
        "            second_kp = matched_second_res['keypoints']\n",
        "            if yolo_kp.shape == (17, 2) and second_kp.shape == (17, 2):\n",
        "                # Разница между ключевыми точками\n",
        "                diff = yolo_kp - second_kp\n",
        "                mae = np.mean(np.abs(diff))\n",
        "                mse = np.mean(diff ** 2)\n",
        "\n",
        "                # Добавление метрик в список\n",
        "                iou_list.append(max_iou)\n",
        "                mae_list.append(mae)\n",
        "                mse_list.append(mse)\n",
        "\n",
        "    # Визуализация для YOLO\n",
        "    annotated_frame_yolo = yolo_results[0].plot()\n",
        "    out_yolo.write(annotated_frame_yolo)\n",
        "\n",
        "    # Визуализация для второй модели\n",
        "    frame_second = frame.copy()\n",
        "    for res in second_results:\n",
        "        l, t, r, b = res['bbox']\n",
        "        cv2.rectangle(frame_second, (int(l), int(t)), (int(r), int(b)), (0, 255, 0), 2)\n",
        "        if 'keypoints' in res:\n",
        "            for kp in res['keypoints']:\n",
        "                cv2.putText(frame_second, f\"ID: {res['track_id']}\", (int(l), int(t) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "                cv2.circle(frame_second, tuple(kp.astype(int)), 5, (0, 0, 255), -1)\n",
        "    out_second.write(frame_second)\n",
        "\n",
        "# Закрытие видеофайлов и освобождение ресурсов\n",
        "cap.release()\n",
        "out_yolo.release()\n",
        "out_second.release()\n",
        "\n",
        "\n",
        "# Расчёт средних значений метрик\n",
        "mean_iou = np.mean(iou_list) if iou_list else 0\n",
        "mean_mae = np.mean(mae_list) if mae_list else 0\n",
        "mean_mse = np.mean(mse_list) if mse_list else 0\n",
        "\n",
        "# Среднее время обработки\n",
        "mean_yolo_time = np.mean(yolo_times)\n",
        "mean_second_model_time = np.mean(second_model_times)\n",
        "\n",
        "# Вывод статистики\n",
        "print(f\"Путь к исходному видео: {video_path}\")\n",
        "print(f\"Путь к сохранённому видео с результатами YOLO:\")\n",
        "print(f\"{yolo_output_path}\")\n",
        "print(f\"Путь к сохранённому видео с результатами второй модели:\")\n",
        "print(f\"{second_output_path}\")\n",
        "print(f\"Средний IOU: {mean_iou:.4f}\")\n",
        "print(f\"Средний MAE: {mean_mae:.4f}\")\n",
        "print(f\"Средний MSE: {mean_mse:.4f}\")\n",
        "print(f\"Среднее время обработки кадра моделью YOLO: {mean_yolo_time:.4f} сек.\")\n",
        "print(f\"Среднее время обработки кадра второй моделью: {mean_second_model_time:.4f} сек.\")\n"
      ],
      "metadata": {
        "id": "HOO7V7iodXPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d6664d9-8761-4fbf-d523-21f1757abf78"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loads checkpoint by local backend from path: hrnet_w48_coco_256x192.pth\n",
            "▶️ Обработка видео: input_video.mp4, кадры 2152-3226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1075 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/1075 [00:00<07:13,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 2.9ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 2/1075 [00:00<05:03,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 2.4ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 3/1075 [00:01<06:57,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 4/1075 [00:01<08:51,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 2.8ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 5/1075 [00:02<09:49,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.5ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 6/1075 [00:03<10:27,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 2.5ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 7/1075 [00:03<10:45,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 8/1075 [00:04<12:06,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.4ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 9/1075 [00:05<13:40,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.8ms\n",
            "Speed: 2.4ms preprocess, 13.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 10/1075 [00:06<14:55,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.0ms\n",
            "Speed: 2.0ms preprocess, 15.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 11/1075 [00:07<14:30,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.5ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 12/1075 [00:08<14:18,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 13/1075 [00:08<14:32,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 2.5ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 14/1075 [00:09<14:54,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 15/1075 [00:10<15:17,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.4ms\n",
            "Speed: 2.6ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 16/1075 [00:11<15:35,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 17/1075 [00:12<15:52,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.2ms\n",
            "Speed: 2.6ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 18/1075 [00:13<15:58,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 19/1075 [00:14<16:07,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 2.5ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 20/1075 [00:15<18:02,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.7ms\n",
            "Speed: 4.7ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 21/1075 [00:16<18:10,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 3.2ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 22/1075 [00:18<19:28,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 21.3ms\n",
            "Speed: 2.5ms preprocess, 21.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 23/1075 [00:19<19:05,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 3.5ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 24/1075 [00:20<17:54,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 25/1075 [00:20<17:25,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 26/1075 [00:21<16:44,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 2.6ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 27/1075 [00:22<16:11,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 28/1075 [00:23<15:52,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 2.8ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 29/1075 [00:24<15:41,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 30/1075 [00:25<15:18,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 2.4ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 31/1075 [00:26<15:15,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 32/1075 [00:26<15:02,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 2.7ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 33/1075 [00:27<14:37,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 1.9ms preprocess, 17.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 34/1075 [00:28<14:23,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 3.0ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 35/1075 [00:29<15:41,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 3.0ms preprocess, 15.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 36/1075 [00:30<17:21,  1.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 2.5ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 37/1075 [00:31<16:12,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 2.5ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 38/1075 [00:32<15:32,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.6ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 39/1075 [00:33<15:02,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 2.4ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 40/1075 [00:34<14:57,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.6ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 41/1075 [00:34<14:32,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 2.6ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 42/1075 [00:35<14:38,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 43/1075 [00:36<14:27,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.2ms preprocess, 14.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 44/1075 [00:37<14:38,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.4ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 45/1075 [00:38<14:20,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 2.4ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 46/1075 [00:39<14:06,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 47/1075 [00:39<14:01,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.5ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 48/1075 [00:40<13:53,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 2.5ms preprocess, 15.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 49/1075 [00:41<15:21,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.0ms\n",
            "Speed: 2.5ms preprocess, 18.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 50/1075 [00:42<16:59,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.8ms\n",
            "Speed: 2.6ms preprocess, 17.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 51/1075 [00:43<16:23,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.5ms\n",
            "Speed: 2.5ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 52/1075 [00:44<15:52,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.4ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 53/1075 [00:45<15:06,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 2.5ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 54/1075 [00:46<14:32,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 55/1075 [00:46<13:51,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.9ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 56/1075 [00:47<13:25,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.5ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 57/1075 [00:48<13:20,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 58/1075 [00:49<13:23,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.5ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 59/1075 [00:50<13:13,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.6ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 60/1075 [00:50<13:19,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 3.1ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 61/1075 [00:51<13:49,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 2.1ms preprocess, 13.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 62/1075 [00:52<13:39,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 63/1075 [00:53<14:27,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.3ms\n",
            "Speed: 2.5ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 64/1075 [00:54<15:21,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.5ms preprocess, 15.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 65/1075 [00:55<16:09,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.6ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 66/1075 [00:56<15:44,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.7ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 67/1075 [00:57<15:22,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 68/1075 [00:58<15:13,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.7ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 69/1075 [00:59<14:49,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 70/1075 [00:59<14:52,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 9.2ms\n",
            "Speed: 2.5ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 71/1075 [01:00<14:44,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 2.5ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 72/1075 [01:01<14:44,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 3.4ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 73/1075 [01:02<14:15,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 74/1075 [01:03<13:50,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.9ms\n",
            "Speed: 2.4ms preprocess, 18.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 75/1075 [01:04<13:38,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.5ms\n",
            "Speed: 2.4ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 76/1075 [01:04<13:56,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 77/1075 [01:06<16:14,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.5ms preprocess, 15.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 78/1075 [01:07<18:09,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 20.8ms\n",
            "Speed: 2.7ms preprocess, 20.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 79/1075 [01:08<18:04,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 80/1075 [01:09<17:24,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 2.5ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 81/1075 [01:10<17:00,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.8ms\n",
            "Speed: 2.4ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 82/1075 [01:11<16:29,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 2.7ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 83/1075 [01:12<16:06,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 2.8ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 84/1075 [01:13<16:09,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 85/1075 [01:14<15:59,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 2.3ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 86/1075 [01:15<16:08,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.5ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 87/1075 [01:16<16:06,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.6ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 88/1075 [01:17<16:12,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 3.1ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 89/1075 [01:18<18:04,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.5ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 90/1075 [01:20<19:04,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 2.4ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 91/1075 [01:21<18:57,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 2.4ms preprocess, 17.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 92/1075 [01:22<18:32,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 93/1075 [01:23<18:06,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 94/1075 [01:24<18:17,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 95/1075 [01:25<18:28,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 2.7ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 96/1075 [01:26<18:29,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.7ms\n",
            "Speed: 2.4ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 97/1075 [01:27<18:16,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 98/1075 [01:28<18:05,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.7ms\n",
            "Speed: 2.5ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 99/1075 [01:30<18:33,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 2.6ms preprocess, 16.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 100/1075 [01:31<20:06,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 21.3ms\n",
            "Speed: 2.5ms preprocess, 21.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 101/1075 [01:32<19:31,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 2.6ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 102/1075 [01:33<18:49,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 103/1075 [01:34<18:43,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.3ms\n",
            "Speed: 2.6ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 104/1075 [01:36<18:16,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 105/1075 [01:37<18:03,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 2.5ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 106/1075 [01:38<18:32,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.4ms preprocess, 15.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 107/1075 [01:39<18:12,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 2.8ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 108/1075 [01:40<17:45,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.8ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 109/1075 [01:41<17:32,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 110/1075 [01:42<18:32,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.8ms\n",
            "Speed: 2.6ms preprocess, 18.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 111/1075 [01:44<20:04,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 112/1075 [01:45<19:52,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 2.5ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 113/1075 [01:46<19:44,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 2.4ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 114/1075 [01:47<18:51,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 115/1075 [01:48<18:56,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 116/1075 [01:50<18:48,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.5ms preprocess, 14.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 117/1075 [01:51<18:25,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 2.4ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 118/1075 [01:52<17:41,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 20.2ms\n",
            "Speed: 2.5ms preprocess, 20.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 119/1075 [01:53<18:04,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.9ms\n",
            "Speed: 2.4ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 120/1075 [01:54<18:38,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.1ms\n",
            "Speed: 2.3ms preprocess, 16.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 121/1075 [01:56<20:00,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 21.2ms\n",
            "Speed: 2.6ms preprocess, 21.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 122/1075 [01:57<19:06,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 123/1075 [01:58<18:32,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 2.6ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 124/1075 [01:59<18:04,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 125/1075 [02:00<17:43,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 126/1075 [02:01<19:14,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.8ms\n",
            "Speed: 2.7ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 127/1075 [02:03<18:58,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.7ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 128/1075 [02:04<18:12,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.5ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 129/1075 [02:05<17:46,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.6ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 130/1075 [02:06<17:41,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.4ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 131/1075 [02:07<19:05,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.5ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 132/1075 [02:09<20:09,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.1ms preprocess, 13.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 133/1075 [02:10<19:03,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 134/1075 [02:11<19:00,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.4ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 135/1075 [02:12<18:47,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.4ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 136/1075 [02:13<18:17,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 2.5ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 137/1075 [02:14<18:03,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 9.6ms\n",
            "Speed: 2.4ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 138/1075 [02:15<17:51,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.7ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 139/1075 [02:17<17:38,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 140/1075 [02:18<17:38,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 2.5ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 141/1075 [02:19<18:57,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 4.7ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 142/1075 [02:21<20:54,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 143/1075 [02:22<20:33,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 144/1075 [02:23<19:40,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 20.3ms\n",
            "Speed: 2.6ms preprocess, 20.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 145/1075 [02:24<19:31,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 2.8ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 146/1075 [02:26<19:09,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.7ms\n",
            "Speed: 2.5ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 147/1075 [02:27<19:07,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.6ms\n",
            "Speed: 3.5ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 148/1075 [02:28<19:15,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 149/1075 [02:29<19:08,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 2.6ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 150/1075 [02:31<19:12,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 2.9ms preprocess, 17.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 151/1075 [02:32<20:21,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 19.8ms\n",
            "Speed: 2.5ms preprocess, 19.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 152/1075 [02:33<20:11,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 153/1075 [02:34<19:20,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 154/1075 [02:36<19:20,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.4ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 155/1075 [02:37<18:48,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.4ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 156/1075 [02:38<19:14,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 5.4ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 157/1075 [02:39<19:09,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 4.4ms preprocess, 14.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 158/1075 [02:41<18:38,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.5ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 159/1075 [02:42<18:13,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.4ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 160/1075 [02:43<19:23,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 19.7ms\n",
            "Speed: 2.5ms preprocess, 19.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 161/1075 [02:45<21:28,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 20.0ms\n",
            "Speed: 2.5ms preprocess, 20.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 162/1075 [02:46<20:12,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 2.4ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 163/1075 [02:47<19:00,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 21.0ms\n",
            "Speed: 2.7ms preprocess, 21.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 164/1075 [02:48<18:49,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 2.4ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 165/1075 [02:49<18:19,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 166/1075 [02:51<18:24,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 2.6ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 167/1075 [02:52<18:21,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 168/1075 [02:53<18:27,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 2.4ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 169/1075 [02:54<18:28,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 17.5ms\n",
            "Speed: 2.5ms preprocess, 17.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 170/1075 [02:56<19:30,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 16.3ms\n",
            "Speed: 2.9ms preprocess, 16.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 171/1075 [02:58<21:17,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 19.0ms\n",
            "Speed: 2.5ms preprocess, 19.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 172/1075 [02:59<20:18,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 15.8ms\n",
            "Speed: 2.6ms preprocess, 15.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 173/1075 [03:00<19:31,  1.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.5ms\n",
            "Speed: 3.0ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 174/1075 [03:01<18:53,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.5ms\n",
            "Speed: 2.8ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▋        | 175/1075 [03:02<18:22,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▋        | 176/1075 [03:04<18:33,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▋        | 177/1075 [03:05<18:59,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 2.4ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 178/1075 [03:06<19:07,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 13.8ms\n",
            "Speed: 2.4ms preprocess, 13.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 179/1075 [03:07<18:54,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.2ms\n",
            "Speed: 2.5ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 180/1075 [03:09<21:22,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.5ms\n",
            "Speed: 2.5ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 181/1075 [03:11<21:01,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.4ms\n",
            "Speed: 2.1ms preprocess, 14.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 182/1075 [03:12<20:15,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 2.5ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 183/1075 [03:13<19:56,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.7ms\n",
            "Speed: 2.5ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 184/1075 [03:14<19:52,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.2ms\n",
            "Speed: 2.9ms preprocess, 16.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 185/1075 [03:16<19:40,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 2.4ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 186/1075 [03:17<19:33,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 187/1075 [03:18<19:38,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 2.4ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 188/1075 [03:20<20:05,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.9ms\n",
            "Speed: 2.4ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 189/1075 [03:22<21:46,  1.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 18.8ms\n",
            "Speed: 2.5ms preprocess, 18.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 190/1075 [03:23<21:11,  1.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 2.5ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 191/1075 [03:24<20:52,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 2.7ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 192/1075 [03:26<20:46,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 20.0ms\n",
            "Speed: 2.5ms preprocess, 20.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 193/1075 [03:27<20:07,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 194/1075 [03:28<19:23,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.6ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 195/1075 [03:29<19:09,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.7ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 196/1075 [03:31<18:52,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 2.7ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 197/1075 [03:32<19:03,  1.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 2.5ms preprocess, 15.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 198/1075 [03:34<20:57,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.6ms preprocess, 17.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▊        | 199/1075 [03:35<20:35,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 20.4ms\n",
            "Speed: 2.5ms preprocess, 20.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▊        | 200/1075 [03:36<20:27,  1.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▊        | 201/1075 [03:38<19:58,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 2.6ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 202/1075 [03:39<19:25,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.4ms\n",
            "Speed: 2.5ms preprocess, 16.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 203/1075 [03:40<18:49,  1.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.4ms\n",
            "Speed: 2.6ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 204/1075 [03:42<18:38,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.0ms\n",
            "Speed: 2.0ms preprocess, 15.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 205/1075 [03:43<18:30,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 2.6ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 206/1075 [03:44<18:38,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.4ms\n",
            "Speed: 2.4ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 207/1075 [03:46<21:04,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.1ms\n",
            "Speed: 2.5ms preprocess, 14.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 208/1075 [03:48<22:45,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.9ms\n",
            "Speed: 3.5ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 209/1075 [03:49<22:05,  1.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 210/1075 [03:51<21:48,  1.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 2.6ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 211/1075 [03:52<21:26,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 2.6ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 212/1075 [03:53<20:57,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.1ms\n",
            "Speed: 2.4ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 213/1075 [03:55<20:15,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 2.5ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 214/1075 [03:56<20:36,  1.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.8ms\n",
            "Speed: 2.5ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 215/1075 [03:58<21:50,  1.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 21.4ms\n",
            "Speed: 2.4ms preprocess, 21.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 216/1075 [04:00<22:15,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 2.4ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 217/1075 [04:01<21:08,  1.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.4ms\n",
            "Speed: 2.9ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 218/1075 [04:02<20:24,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 219/1075 [04:04<19:52,  1.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.2ms\n",
            "Speed: 2.5ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 220/1075 [04:05<19:15,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 221/1075 [04:06<19:27,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.3ms\n",
            "Speed: 2.5ms preprocess, 16.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 222/1075 [04:08<19:19,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.3ms\n",
            "Speed: 2.4ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 223/1075 [04:09<18:49,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 2.5ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 224/1075 [04:11<20:47,  1.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 19.8ms\n",
            "Speed: 2.5ms preprocess, 19.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 225/1075 [04:12<20:40,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.0ms\n",
            "Speed: 2.9ms preprocess, 16.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 226/1075 [04:13<20:08,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 2.5ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 227/1075 [04:15<19:37,  1.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 228/1075 [04:16<19:18,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.6ms\n",
            "Speed: 3.3ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 229/1075 [04:17<19:28,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 2.9ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 230/1075 [04:19<19:09,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.3ms\n",
            "Speed: 2.4ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 231/1075 [04:20<19:08,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.7ms\n",
            "Speed: 2.6ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 232/1075 [04:22<20:07,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.4ms\n",
            "Speed: 4.4ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 233/1075 [04:24<21:51,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.5ms\n",
            "Speed: 3.2ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 234/1075 [04:25<21:21,  1.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 2.8ms preprocess, 15.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 235/1075 [04:26<20:57,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.5ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 236/1075 [04:28<20:39,  1.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 2.5ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 237/1075 [04:29<20:22,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.3ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 238/1075 [04:31<19:42,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.7ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 239/1075 [04:32<19:13,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 2.4ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 240/1075 [04:33<19:07,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 2.4ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 241/1075 [04:35<20:52,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 19.0ms\n",
            "Speed: 2.4ms preprocess, 19.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 242/1075 [04:37<21:00,  1.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.6ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 243/1075 [04:38<20:04,  1.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 3.9ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 244/1075 [04:39<19:59,  1.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 2.5ms preprocess, 16.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 245/1075 [04:41<19:22,  1.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 246/1075 [04:42<19:17,  1.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.5ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 247/1075 [04:43<19:39,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.2ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 248/1075 [04:45<19:04,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.5ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 249/1075 [04:47<20:24,  1.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.5ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 250/1075 [04:48<21:47,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 251/1075 [04:50<20:51,  1.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 2.9ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 252/1075 [04:51<20:20,  1.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.4ms\n",
            "Speed: 4.3ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 253/1075 [04:52<19:50,  1.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 2.4ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 254/1075 [04:54<20:02,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.6ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 255/1075 [04:55<19:46,  1.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.5ms preprocess, 15.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 256/1075 [04:57<20:00,  1.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 2.4ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 257/1075 [04:59<21:29,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.5ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 258/1075 [05:01<23:23,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 3.0ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 259/1075 [05:02<22:30,  1.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 3.9ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 260/1075 [05:04<22:21,  1.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.6ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 261/1075 [05:05<21:41,  1.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 3.0ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 262/1075 [05:07<21:19,  1.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 2.8ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 263/1075 [05:08<21:12,  1.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.5ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 264/1075 [05:10<21:26,  1.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 20.0ms\n",
            "Speed: 2.6ms preprocess, 20.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 265/1075 [05:12<23:08,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 2.8ms preprocess, 17.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 266/1075 [05:14<23:15,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 3.4ms preprocess, 16.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 267/1075 [05:15<22:49,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 2.7ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 268/1075 [05:17<22:10,  1.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 2.5ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 269/1075 [05:19<21:42,  1.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.6ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 270/1075 [05:20<22:17,  1.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 2.8ms preprocess, 16.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 271/1075 [05:22<21:24,  1.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 2.4ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 272/1075 [05:23<21:46,  1.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 20.1ms\n",
            "Speed: 2.5ms preprocess, 20.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 273/1075 [05:25<23:07,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 2.4ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 274/1075 [05:27<22:10,  1.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.5ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 275/1075 [05:28<21:21,  1.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.9ms\n",
            "Speed: 2.7ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 276/1075 [05:30<21:01,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.1ms\n",
            "Speed: 2.9ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 277/1075 [05:32<21:04,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 2.6ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 278/1075 [05:33<21:00,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.5ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 279/1075 [05:35<20:32,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 280/1075 [05:36<21:44,  1.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.4ms\n",
            "Speed: 2.5ms preprocess, 17.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 281/1075 [05:38<22:34,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.5ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 282/1075 [05:40<22:12,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.7ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 283/1075 [05:41<21:19,  1.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.8ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 284/1075 [05:43<20:25,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 2.5ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 285/1075 [05:44<20:05,  1.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.7ms\n",
            "Speed: 2.5ms preprocess, 16.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 286/1075 [05:46<19:25,  1.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 2.6ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 287/1075 [05:47<18:29,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 288/1075 [05:48<19:15,  1.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 5.3ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 289/1075 [05:50<20:05,  1.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.2ms\n",
            "Speed: 2.7ms preprocess, 18.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 290/1075 [05:51<19:04,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 291/1075 [05:53<18:05,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.7ms\n",
            "Speed: 2.8ms preprocess, 15.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 292/1075 [05:54<17:22,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 293/1075 [05:55<17:19,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 19.1ms\n",
            "Speed: 3.4ms preprocess, 19.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 294/1075 [05:56<17:14,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.1ms\n",
            "Speed: 3.0ms preprocess, 15.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 295/1075 [05:58<16:52,  1.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 3.1ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 296/1075 [05:59<16:39,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.3ms\n",
            "Speed: 2.5ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 297/1075 [06:00<17:11,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 17.9ms\n",
            "Speed: 2.3ms preprocess, 17.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 298/1075 [06:02<18:31,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.5ms\n",
            "Speed: 2.5ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 299/1075 [06:03<17:38,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 300/1075 [06:04<16:18,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.9ms\n",
            "Speed: 2.4ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 301/1075 [06:05<15:15,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 2.4ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 302/1075 [06:06<14:39,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 303/1075 [06:07<13:31,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.5ms\n",
            "Speed: 2.5ms preprocess, 15.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 304/1075 [06:08<11:24,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 2.6ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 305/1075 [06:08<09:53,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 3.0ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 306/1075 [06:09<08:51,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 2.9ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 307/1075 [06:09<08:07,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 2.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 308/1075 [06:10<07:50,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 2.5ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 309/1075 [06:10<07:26,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.8ms\n",
            "Speed: 2.4ms preprocess, 16.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 310/1075 [06:11<07:21,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.5ms\n",
            "Speed: 3.6ms preprocess, 15.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 311/1075 [06:11<07:03,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 2.5ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 312/1075 [06:12<07:04,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.8ms\n",
            "Speed: 2.4ms preprocess, 15.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 313/1075 [06:13<07:45,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 314/1075 [06:13<07:59,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 24.3ms\n",
            "Speed: 2.7ms preprocess, 24.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 315/1075 [06:14<08:31,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 17.0ms\n",
            "Speed: 2.5ms preprocess, 17.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 316/1075 [06:15<08:04,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 26.3ms\n",
            "Speed: 2.5ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 317/1075 [06:15<07:44,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 318/1075 [06:16<07:27,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.6ms\n",
            "Speed: 2.4ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 319/1075 [06:16<07:09,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 2.8ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 320/1075 [06:17<07:13,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 321/1075 [06:17<06:58,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.4ms\n",
            "Speed: 3.1ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 322/1075 [06:18<06:53,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.9ms\n",
            "Speed: 2.4ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 323/1075 [06:18<06:43,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 324/1075 [06:19<06:39,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 325/1075 [06:19<06:20,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.4ms\n",
            "Speed: 2.7ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 326/1075 [06:20<06:16,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.9ms\n",
            "Speed: 2.5ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 327/1075 [06:20<06:07,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 2.9ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 328/1075 [06:21<05:57,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 329/1075 [06:21<05:54,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 2.8ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 330/1075 [06:22<05:57,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.6ms\n",
            "Speed: 2.5ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 331/1075 [06:22<05:51,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.5ms\n",
            "Speed: 2.5ms preprocess, 14.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 332/1075 [06:23<05:47,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 17.9ms\n",
            "Speed: 2.4ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 333/1075 [06:23<05:47,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 2.9ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 334/1075 [06:24<05:51,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 335/1075 [06:24<06:20,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.0ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 336/1075 [06:25<07:40,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 20.7ms\n",
            "Speed: 2.5ms preprocess, 20.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 337/1075 [06:26<08:35,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 15.1ms\n",
            "Speed: 2.6ms preprocess, 15.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 338/1075 [06:27<08:39,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 19.7ms\n",
            "Speed: 2.6ms preprocess, 19.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 339/1075 [06:27<08:03,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 340/1075 [06:28<07:38,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.5ms\n",
            "Speed: 2.5ms preprocess, 16.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 341/1075 [06:28<07:30,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.0ms\n",
            "Speed: 2.9ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 342/1075 [06:29<07:07,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 2.5ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 343/1075 [06:29<06:54,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 2.6ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 344/1075 [06:30<06:52,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 2.5ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 345/1075 [06:31<07:00,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.2ms\n",
            "Speed: 2.8ms preprocess, 16.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 346/1075 [06:31<07:17,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.1ms\n",
            "Speed: 2.6ms preprocess, 15.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 347/1075 [06:32<07:29,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 17.8ms\n",
            "Speed: 2.5ms preprocess, 17.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 348/1075 [06:33<07:40,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.2ms\n",
            "Speed: 2.5ms preprocess, 15.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 349/1075 [06:33<07:44,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 2.6ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 350/1075 [06:34<07:46,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.5ms\n",
            "Speed: 2.4ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 351/1075 [06:35<07:55,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.9ms\n",
            "Speed: 2.5ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 352/1075 [06:35<08:05,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.8ms\n",
            "Speed: 2.6ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 353/1075 [06:36<08:12,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 2.8ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 354/1075 [06:37<08:35,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 23.8ms\n",
            "Speed: 2.5ms preprocess, 23.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 355/1075 [06:38<09:15,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 17.7ms\n",
            "Speed: 3.1ms preprocess, 17.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 356/1075 [06:39<10:12,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.0ms\n",
            "Speed: 2.7ms preprocess, 16.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 357/1075 [06:40<10:13,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.0ms\n",
            "Speed: 2.8ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 358/1075 [06:40<10:04,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 359/1075 [06:41<09:58,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 2.8ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 360/1075 [06:42<09:40,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.2ms\n",
            "Speed: 3.4ms preprocess, 14.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▎      | 361/1075 [06:43<09:22,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 2.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▎      | 362/1075 [06:43<09:11,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 17.3ms\n",
            "Speed: 3.7ms preprocess, 17.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 363/1075 [06:44<08:56,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 2.4ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 364/1075 [06:45<08:45,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.2ms\n",
            "Speed: 5.9ms preprocess, 15.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 365/1075 [06:46<08:50,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 2.7ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 366/1075 [06:46<09:00,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.4ms\n",
            "Speed: 2.3ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 367/1075 [06:47<08:44,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.8ms\n",
            "Speed: 3.1ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 368/1075 [06:48<08:42,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 369/1075 [06:49<08:49,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 15.9ms\n",
            "Speed: 2.9ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 370/1075 [06:50<09:53,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 18.3ms\n",
            "Speed: 2.5ms preprocess, 18.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 371/1075 [06:51<10:44,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 17.3ms\n",
            "Speed: 2.7ms preprocess, 17.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 372/1075 [06:52<10:46,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 373/1075 [06:52<10:22,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 17.7ms\n",
            "Speed: 2.4ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 374/1075 [06:53<10:03,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 14.9ms\n",
            "Speed: 2.5ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 375/1075 [06:54<10:03,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 12.5ms\n",
            "Speed: 2.5ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 376/1075 [06:55<09:53,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 377/1075 [06:56<09:37,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 2.5ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 378/1075 [06:57<09:37,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 2.8ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 379/1075 [06:57<09:25,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.2ms\n",
            "Speed: 2.5ms preprocess, 15.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 380/1075 [06:58<09:16,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.9ms\n",
            "Speed: 2.5ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 381/1075 [06:59<09:24,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 2.6ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 382/1075 [07:00<09:26,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.2ms\n",
            "Speed: 2.6ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 383/1075 [07:01<09:43,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 2.7ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 384/1075 [07:02<10:21,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 4 persons, 18.6ms\n",
            "Speed: 2.5ms preprocess, 18.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 385/1075 [07:03<11:24,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 4 persons, 18.4ms\n",
            "Speed: 2.6ms preprocess, 18.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 386/1075 [07:04<11:54,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 4 persons, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 387/1075 [07:05<11:26,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 12.5ms\n",
            "Speed: 2.5ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 388/1075 [07:06<11:16,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 389/1075 [07:07<11:22,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 2.5ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▋      | 390/1075 [07:08<11:11,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.7ms\n",
            "Speed: 2.4ms preprocess, 16.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▋      | 391/1075 [07:09<11:04,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.2ms\n",
            "Speed: 2.4ms preprocess, 14.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▋      | 392/1075 [07:10<10:51,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 2.4ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 393/1075 [07:11<10:25,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 2.5ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 394/1075 [07:12<10:37,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 17.0ms\n",
            "Speed: 2.4ms preprocess, 17.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 395/1075 [07:13<10:54,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 2.5ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 396/1075 [07:14<10:54,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 4 persons, 12.0ms\n",
            "Speed: 2.6ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 397/1075 [07:15<12:17,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 32.7ms\n",
            "Speed: 2.6ms preprocess, 32.7ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 398/1075 [07:16<13:31,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.9ms\n",
            "Speed: 2.6ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 399/1075 [07:18<13:16,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.4ms\n",
            "Speed: 2.5ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 400/1075 [07:19<12:45,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.0ms\n",
            "Speed: 2.7ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 401/1075 [07:20<12:24,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 2.4ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 402/1075 [07:21<12:17,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 13.7ms\n",
            "Speed: 2.7ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 403/1075 [07:22<12:04,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 17.1ms\n",
            "Speed: 2.4ms preprocess, 17.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 404/1075 [07:23<11:51,  1.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.2ms\n",
            "Speed: 2.6ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 405/1075 [07:24<11:42,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.3ms\n",
            "Speed: 2.5ms preprocess, 15.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 406/1075 [07:25<11:27,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.2ms\n",
            "Speed: 2.5ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 407/1075 [07:26<11:35,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 15.6ms\n",
            "Speed: 2.6ms preprocess, 15.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 408/1075 [07:27<12:48,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 18.0ms\n",
            "Speed: 2.7ms preprocess, 18.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 409/1075 [07:29<13:57,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 15.2ms\n",
            "Speed: 3.0ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 410/1075 [07:30<13:24,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 411/1075 [07:31<13:17,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 2.5ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 412/1075 [07:32<13:03,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 13.2ms\n",
            "Speed: 2.4ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 413/1075 [07:33<13:01,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 14.6ms\n",
            "Speed: 3.2ms preprocess, 14.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▊      | 414/1075 [07:34<12:59,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 15.3ms\n",
            "Speed: 2.8ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▊      | 415/1075 [07:36<12:41,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 16.7ms\n",
            "Speed: 2.4ms preprocess, 16.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▊      | 416/1075 [07:37<12:20,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 2.7ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 417/1075 [07:38<12:09,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 12.8ms\n",
            "Speed: 2.7ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 418/1075 [07:39<12:09,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 20.3ms\n",
            "Speed: 2.6ms preprocess, 20.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 419/1075 [07:40<12:44,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 19.0ms\n",
            "Speed: 2.4ms preprocess, 19.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 420/1075 [07:41<12:38,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 13.8ms\n",
            "Speed: 2.7ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 421/1075 [07:42<12:00,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 15.4ms\n",
            "Speed: 2.3ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 422/1075 [07:43<11:10,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 12.6ms\n",
            "Speed: 2.3ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 423/1075 [07:44<10:53,  1.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 2.6ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 424/1075 [07:45<10:44,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.3ms\n",
            "Speed: 7.0ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 425/1075 [07:46<10:32,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.1ms\n",
            "Speed: 2.7ms preprocess, 15.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 426/1075 [07:47<10:22,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.4ms\n",
            "Speed: 2.5ms preprocess, 14.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 427/1075 [07:48<10:06,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 2.4ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 428/1075 [07:49<09:48,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 2.4ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 429/1075 [07:49<09:51,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.2ms\n",
            "Speed: 2.4ms preprocess, 14.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 430/1075 [07:50<09:36,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 15.2ms\n",
            "Speed: 2.6ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 431/1075 [07:51<10:12,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 18.0ms\n",
            "Speed: 2.6ms preprocess, 18.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 432/1075 [07:53<11:12,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 16.9ms\n",
            "Speed: 2.5ms preprocess, 16.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 433/1075 [07:54<11:10,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 13.2ms\n",
            "Speed: 2.5ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 434/1075 [07:55<10:56,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 14.4ms\n",
            "Speed: 2.6ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 435/1075 [07:56<10:56,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 6.6ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 436/1075 [07:57<10:53,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 12.9ms\n",
            "Speed: 2.4ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 437/1075 [07:58<10:28,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 13.1ms\n",
            "Speed: 2.5ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 438/1075 [07:59<10:07,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 2.5ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 439/1075 [07:59<10:03,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 18.3ms\n",
            "Speed: 2.4ms preprocess, 18.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 440/1075 [08:00<10:11,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 15.8ms\n",
            "Speed: 3.0ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 441/1075 [08:01<09:44,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 13.2ms\n",
            "Speed: 2.6ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 442/1075 [08:02<09:40,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 15.0ms\n",
            "Speed: 2.6ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 443/1075 [08:03<09:31,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 15.8ms\n",
            "Speed: 2.8ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 444/1075 [08:04<10:09,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 22.8ms\n",
            "Speed: 2.5ms preprocess, 22.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 445/1075 [08:06<11:18,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 14.5ms\n",
            "Speed: 2.4ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████▏     | 446/1075 [08:06<10:33,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 14.9ms\n",
            "Speed: 2.5ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 447/1075 [08:07<09:59,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 4.6ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 448/1075 [08:08<09:29,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 16.9ms\n",
            "Speed: 2.5ms preprocess, 16.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 449/1075 [08:09<09:22,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 2.5ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 450/1075 [08:10<09:10,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 16.1ms\n",
            "Speed: 2.5ms preprocess, 16.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 451/1075 [08:11<09:11,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 16.2ms\n",
            "Speed: 2.5ms preprocess, 16.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 452/1075 [08:11<08:48,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 15.3ms\n",
            "Speed: 2.5ms preprocess, 15.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 453/1075 [08:12<08:26,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 14.6ms\n",
            "Speed: 2.6ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 454/1075 [08:13<08:18,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 15.0ms\n",
            "Speed: 3.4ms preprocess, 15.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 455/1075 [08:14<08:07,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 2.7ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 456/1075 [08:14<08:17,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 2.5ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 457/1075 [08:15<08:27,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 16.2ms\n",
            "Speed: 2.6ms preprocess, 16.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 458/1075 [08:16<09:07,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 20.0ms\n",
            "Speed: 2.4ms preprocess, 20.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 459/1075 [08:17<09:44,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 16.6ms\n",
            "Speed: 2.5ms preprocess, 16.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 460/1075 [08:18<09:11,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.4ms\n",
            "Speed: 2.5ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 461/1075 [08:19<08:31,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 14.1ms\n",
            "Speed: 2.5ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 462/1075 [08:20<08:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 2.5ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 463/1075 [08:20<07:29,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 14.6ms\n",
            "Speed: 2.4ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 464/1075 [08:21<07:07,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 12.1ms\n",
            "Speed: 2.6ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 465/1075 [08:22<07:05,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 12.8ms\n",
            "Speed: 2.7ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 466/1075 [08:22<06:58,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 467/1075 [08:23<06:55,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 15.6ms\n",
            "Speed: 3.5ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▎     | 468/1075 [08:23<06:41,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 14.7ms\n",
            "Speed: 2.5ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▎     | 469/1075 [08:24<06:32,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 14.6ms\n",
            "Speed: 2.5ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▎     | 470/1075 [08:25<06:36,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 2.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 471/1075 [08:25<06:33,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 13.9ms\n",
            "Speed: 2.4ms preprocess, 13.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 472/1075 [08:26<06:31,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 13.5ms\n",
            "Speed: 2.5ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 473/1075 [08:27<06:23,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 13.9ms\n",
            "Speed: 2.6ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 474/1075 [08:27<06:19,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 16.4ms\n",
            "Speed: 2.7ms preprocess, 16.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 475/1075 [08:28<06:20,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 19.0ms\n",
            "Speed: 2.7ms preprocess, 19.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 476/1075 [08:29<06:58,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 12.8ms\n",
            "Speed: 2.6ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 477/1075 [08:30<07:34,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 21.0ms\n",
            "Speed: 2.6ms preprocess, 21.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 478/1075 [08:31<08:04,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 17.4ms\n",
            "Speed: 3.0ms preprocess, 17.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 479/1075 [08:31<07:56,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 15.1ms\n",
            "Speed: 2.5ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 480/1075 [08:32<07:30,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 12.6ms\n",
            "Speed: 2.4ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 481/1075 [08:33<07:20,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 13.6ms\n",
            "Speed: 2.4ms preprocess, 13.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 482/1075 [08:34<07:39,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 483/1075 [08:34<07:53,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 16.5ms\n",
            "Speed: 2.6ms preprocess, 16.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 484/1075 [08:35<08:01,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 21.9ms\n",
            "Speed: 2.5ms preprocess, 21.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 485/1075 [08:36<08:06,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 14.8ms\n",
            "Speed: 2.6ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 486/1075 [08:37<08:06,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 14.0ms\n",
            "Speed: 2.5ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 487/1075 [08:38<08:08,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 2.7ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 488/1075 [08:39<08:07,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 13.2ms\n",
            "Speed: 2.4ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 489/1075 [08:40<08:24,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 15.9ms\n",
            "Speed: 2.6ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 490/1075 [08:41<08:43,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 20.8ms\n",
            "Speed: 2.5ms preprocess, 20.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 491/1075 [08:42<09:40,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.1ms\n",
            "Speed: 3.7ms preprocess, 16.1ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 492/1075 [08:43<10:37,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.9ms\n",
            "Speed: 3.1ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 493/1075 [08:44<10:18,  1.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 494/1075 [08:45<11:04,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.0ms\n",
            "Speed: 2.4ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 495/1075 [08:47<11:22,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 17.7ms\n",
            "Speed: 2.8ms preprocess, 17.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 496/1075 [08:48<11:26,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.2ms\n",
            "Speed: 2.9ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 497/1075 [08:49<11:39,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.1ms\n",
            "Speed: 2.9ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▋     | 498/1075 [08:50<11:43,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 2.9ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▋     | 499/1075 [08:52<11:42,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.5ms\n",
            "Speed: 2.5ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 500/1075 [08:53<11:37,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 17.0ms\n",
            "Speed: 2.5ms preprocess, 17.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 501/1075 [08:54<12:52,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.3ms\n",
            "Speed: 2.7ms preprocess, 15.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 502/1075 [08:56<12:55,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 2.8ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 503/1075 [08:57<12:39,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 2.6ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 504/1075 [08:58<12:14,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.5ms\n",
            "Speed: 2.6ms preprocess, 16.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 505/1075 [09:00<12:10,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.9ms\n",
            "Speed: 2.5ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 506/1075 [09:01<12:17,  1.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.8ms\n",
            "Speed: 2.5ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 507/1075 [09:02<12:45,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 2.4ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 508/1075 [09:04<12:48,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.3ms\n",
            "Speed: 2.5ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 509/1075 [09:05<12:23,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.9ms\n",
            "Speed: 2.8ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 510/1075 [09:07<13:28,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.6ms\n",
            "Speed: 2.5ms preprocess, 15.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 511/1075 [09:08<13:36,  1.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.0ms\n",
            "Speed: 3.0ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 512/1075 [09:09<12:56,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.9ms\n",
            "Speed: 2.4ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 513/1075 [09:11<12:26,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.7ms\n",
            "Speed: 2.9ms preprocess, 16.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 514/1075 [09:12<12:06,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 2.9ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 515/1075 [09:13<11:53,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.6ms\n",
            "Speed: 2.4ms preprocess, 13.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 516/1075 [09:14<11:41,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 17.5ms\n",
            "Speed: 2.4ms preprocess, 17.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 517/1075 [09:15<10:33,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.4ms\n",
            "Speed: 2.4ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 518/1075 [09:16<10:01,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 18.2ms\n",
            "Speed: 2.4ms preprocess, 18.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 519/1075 [09:17<09:28,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.7ms\n",
            "Speed: 2.5ms preprocess, 15.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 520/1075 [09:18<09:54,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 21.3ms\n",
            "Speed: 2.3ms preprocess, 21.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 521/1075 [09:19<10:18,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 18.2ms\n",
            "Speed: 2.6ms preprocess, 18.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▊     | 522/1075 [09:20<10:05,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 2.6ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▊     | 523/1075 [09:21<09:29,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.7ms\n",
            "Speed: 2.4ms preprocess, 14.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▊     | 524/1075 [09:22<08:57,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.4ms\n",
            "Speed: 2.7ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 525/1075 [09:23<08:40,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.5ms\n",
            "Speed: 2.6ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 526/1075 [09:24<08:28,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.2ms\n",
            "Speed: 2.8ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 527/1075 [09:25<08:15,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.1ms\n",
            "Speed: 2.4ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 528/1075 [09:26<08:11,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.6ms\n",
            "Speed: 2.8ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 529/1075 [09:26<08:05,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.2ms\n",
            "Speed: 2.7ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 530/1075 [09:27<07:47,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 531/1075 [09:28<07:34,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.5ms\n",
            "Speed: 2.4ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 532/1075 [09:29<07:36,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.1ms\n",
            "Speed: 2.4ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|████▉     | 533/1075 [09:30<07:31,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.8ms\n",
            "Speed: 2.6ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|████▉     | 534/1075 [09:31<08:12,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 17.5ms\n",
            "Speed: 2.4ms preprocess, 17.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|████▉     | 535/1075 [09:32<09:06,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.6ms\n",
            "Speed: 2.5ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|████▉     | 536/1075 [09:33<08:31,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.6ms\n",
            "Speed: 2.8ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|████▉     | 537/1075 [09:34<08:23,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 538/1075 [09:35<08:05,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 539/1075 [09:35<07:45,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.4ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 540/1075 [09:36<07:29,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.4ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 541/1075 [09:37<07:30,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 2.4ms preprocess, 13.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 542/1075 [09:38<07:15,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 21.6ms\n",
            "Speed: 2.3ms preprocess, 21.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 543/1075 [09:39<07:07,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.4ms\n",
            "Speed: 2.3ms preprocess, 16.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 544/1075 [09:39<07:04,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.4ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 545/1075 [09:40<07:10,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.8ms\n",
            "Speed: 2.7ms preprocess, 18.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 546/1075 [09:41<07:17,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 3.5ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 547/1075 [09:42<07:18,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 548/1075 [09:43<07:48,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.9ms\n",
            "Speed: 2.5ms preprocess, 18.9ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 549/1075 [09:44<08:23,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.8ms preprocess, 17.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 550/1075 [09:45<08:05,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.5ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████▏    | 551/1075 [09:46<07:47,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.3ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████▏    | 552/1075 [09:46<07:40,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 21.3ms\n",
            "Speed: 2.4ms preprocess, 21.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████▏    | 553/1075 [09:47<07:35,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.9ms\n",
            "Speed: 2.6ms preprocess, 18.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 554/1075 [09:48<07:27,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.4ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 555/1075 [09:49<07:17,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 2.5ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 556/1075 [09:50<07:07,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.6ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 557/1075 [09:51<07:12,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 14.6ms\n",
            "Speed: 3.3ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 558/1075 [09:51<07:05,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 16.7ms\n",
            "Speed: 2.3ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 559/1075 [09:52<06:58,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 13.4ms\n",
            "Speed: 2.4ms preprocess, 13.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 560/1075 [09:53<06:54,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 2.4ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 561/1075 [09:54<06:51,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 2.5ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 562/1075 [09:55<07:12,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 2.5ms preprocess, 16.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 563/1075 [09:56<07:46,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.4ms\n",
            "Speed: 2.6ms preprocess, 17.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 564/1075 [09:57<08:08,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 3.0ms preprocess, 16.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 565/1075 [09:58<07:21,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 566/1075 [09:58<06:47,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.6ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 567/1075 [09:59<06:14,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.3ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 568/1075 [09:59<05:50,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.5ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 569/1075 [10:00<05:34,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.4ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 570/1075 [10:00<05:19,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.3ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 571/1075 [10:01<05:12,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.5ms preprocess, 15.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 572/1075 [10:02<04:54,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.4ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 573/1075 [10:02<04:37,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.3ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 574/1075 [10:03<04:20,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.4ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 575/1075 [10:03<04:20,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▎    | 576/1075 [10:04<04:22,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.4ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▎    | 577/1075 [10:04<04:28,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 2.4ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 578/1075 [10:05<04:21,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 3.5ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 579/1075 [10:05<04:09,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 3.0ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 580/1075 [10:06<03:59,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.8ms preprocess, 15.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 581/1075 [10:06<04:03,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 2.4ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 582/1075 [10:06<03:54,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.4ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 583/1075 [10:07<04:20,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 2.6ms preprocess, 16.6ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 584/1075 [10:08<04:27,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 2.5ms preprocess, 18.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 585/1075 [10:08<04:43,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.5ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 586/1075 [10:09<04:59,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.5ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 587/1075 [10:09<04:32,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 2.3ms preprocess, 15.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 588/1075 [10:10<04:22,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.4ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 589/1075 [10:10<04:09,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 3.2ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 590/1075 [10:11<03:58,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.5ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 591/1075 [10:11<03:51,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 2.4ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 592/1075 [10:12<03:42,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 593/1075 [10:12<03:38,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.4ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 594/1075 [10:13<03:35,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 4.0ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 595/1075 [10:13<03:40,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 596/1075 [10:14<03:39,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.3ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 597/1075 [10:14<03:37,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 598/1075 [10:14<03:36,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 21.5ms\n",
            "Speed: 2.4ms preprocess, 21.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 599/1075 [10:15<03:40,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.4ms preprocess, 13.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 600/1075 [10:15<03:50,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.4ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 601/1075 [10:16<03:51,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 2.5ms preprocess, 15.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 602/1075 [10:17<04:03,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.4ms\n",
            "Speed: 2.2ms preprocess, 17.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 603/1075 [10:17<04:12,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.3ms preprocess, 15.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 604/1075 [10:18<04:10,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.6ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▋    | 605/1075 [10:18<04:18,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▋    | 606/1075 [10:19<04:18,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.9ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▋    | 607/1075 [10:19<04:31,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.6ms preprocess, 16.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 608/1075 [10:20<04:41,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 2.4ms preprocess, 13.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 609/1075 [10:21<05:03,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.5ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 610/1075 [10:22<05:13,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 611/1075 [10:22<04:49,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.3ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 612/1075 [10:23<04:35,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.3ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 613/1075 [10:23<04:21,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.4ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 614/1075 [10:24<04:15,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 2.3ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 615/1075 [10:24<04:06,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 3.5ms preprocess, 17.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 616/1075 [10:25<04:15,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 24.4ms\n",
            "Speed: 2.5ms preprocess, 24.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 617/1075 [10:25<04:23,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 2.3ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 618/1075 [10:26<04:27,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.4ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 619/1075 [10:27<04:24,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.5ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 620/1075 [10:27<04:30,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 621/1075 [10:28<04:27,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.4ms\n",
            "Speed: 2.5ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 622/1075 [10:28<04:38,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.9ms\n",
            "Speed: 2.8ms preprocess, 13.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 623/1075 [10:29<04:42,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 624/1075 [10:30<04:50,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 2.5ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 625/1075 [10:30<05:01,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.9ms\n",
            "Speed: 2.4ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 626/1075 [10:31<05:21,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.6ms\n",
            "Speed: 2.6ms preprocess, 14.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 627/1075 [10:32<05:59,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.7ms\n",
            "Speed: 2.5ms preprocess, 14.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 628/1075 [10:33<06:46,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 19.3ms\n",
            "Speed: 3.0ms preprocess, 19.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 629/1075 [10:34<06:54,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 2.4ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 630/1075 [10:35<06:49,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.4ms\n",
            "Speed: 2.4ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▊    | 631/1075 [10:36<06:49,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.4ms\n",
            "Speed: 2.4ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 632/1075 [10:37<06:46,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.9ms\n",
            "Speed: 2.4ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 633/1075 [10:38<06:50,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.7ms\n",
            "Speed: 2.6ms preprocess, 14.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 634/1075 [10:39<06:46,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.7ms\n",
            "Speed: 2.3ms preprocess, 14.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 635/1075 [10:40<06:52,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.9ms\n",
            "Speed: 2.2ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 636/1075 [10:41<07:10,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.8ms\n",
            "Speed: 2.5ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 637/1075 [10:42<07:25,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 2.4ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 638/1075 [10:43<07:39,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.9ms\n",
            "Speed: 2.4ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 639/1075 [10:45<08:13,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 21.9ms\n",
            "Speed: 4.5ms preprocess, 21.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 640/1075 [10:46<09:01,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 2.5ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 641/1075 [10:47<08:44,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 20.1ms\n",
            "Speed: 2.8ms preprocess, 20.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 642/1075 [10:48<08:26,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.2ms\n",
            "Speed: 2.4ms preprocess, 15.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 643/1075 [10:49<08:16,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.8ms\n",
            "Speed: 2.6ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 644/1075 [10:51<08:09,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 645/1075 [10:52<08:07,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.8ms\n",
            "Speed: 2.8ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 646/1075 [10:53<08:02,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 647/1075 [10:54<08:14,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.5ms\n",
            "Speed: 3.3ms preprocess, 14.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 648/1075 [10:55<08:10,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 3.0ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 649/1075 [10:56<08:25,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.2ms\n",
            "Speed: 2.3ms preprocess, 17.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 650/1075 [10:58<09:21,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 25.5ms\n",
            "Speed: 2.8ms preprocess, 25.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 651/1075 [10:59<09:02,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 3.0ms preprocess, 15.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 652/1075 [11:01<08:57,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.7ms\n",
            "Speed: 2.4ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 653/1075 [11:02<08:33,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.9ms\n",
            "Speed: 2.4ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 654/1075 [11:03<08:25,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.6ms\n",
            "Speed: 2.6ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 655/1075 [11:04<08:21,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.5ms\n",
            "Speed: 2.3ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 656/1075 [11:05<08:14,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.8ms\n",
            "Speed: 2.8ms preprocess, 16.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 657/1075 [11:06<07:54,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.5ms\n",
            "Speed: 2.5ms preprocess, 16.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 658/1075 [11:07<07:42,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.6ms\n",
            "Speed: 2.8ms preprocess, 14.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████▏   | 659/1075 [11:08<07:43,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.1ms\n",
            "Speed: 2.9ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████▏   | 660/1075 [11:10<08:36,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 2.5ms preprocess, 18.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████▏   | 661/1075 [11:11<09:03,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.4ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 662/1075 [11:12<08:39,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.4ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 663/1075 [11:14<08:35,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.4ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 664/1075 [11:15<08:20,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.6ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 665/1075 [11:16<08:16,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 3.0ms preprocess, 12.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 666/1075 [11:17<08:18,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 19.6ms\n",
            "Speed: 2.5ms preprocess, 19.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 667/1075 [11:19<08:22,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.6ms\n",
            "Speed: 2.2ms preprocess, 17.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 668/1075 [11:20<08:10,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.3ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 669/1075 [11:21<07:52,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 2.4ms preprocess, 16.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 670/1075 [11:22<08:21,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 19.2ms\n",
            "Speed: 2.7ms preprocess, 19.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 671/1075 [11:24<08:39,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.6ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 672/1075 [11:25<08:18,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.4ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 673/1075 [11:26<08:07,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.4ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 674/1075 [11:27<07:53,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.3ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 675/1075 [11:28<07:40,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.4ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 676/1075 [11:29<07:35,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.1ms\n",
            "Speed: 2.8ms preprocess, 18.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 677/1075 [11:30<07:33,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.5ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 678/1075 [11:31<07:40,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 679/1075 [11:33<07:41,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.4ms\n",
            "Speed: 2.6ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 680/1075 [11:34<08:25,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 20.3ms\n",
            "Speed: 2.3ms preprocess, 20.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 681/1075 [11:36<08:49,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.5ms\n",
            "Speed: 2.8ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 682/1075 [11:37<08:23,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▎   | 683/1075 [11:38<08:05,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▎   | 684/1075 [11:39<07:51,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.5ms\n",
            "Speed: 2.3ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▎   | 685/1075 [11:40<07:35,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.1ms\n",
            "Speed: 2.3ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 686/1075 [11:41<07:34,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.2ms\n",
            "Speed: 2.5ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 687/1075 [11:42<07:24,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.7ms\n",
            "Speed: 3.0ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 688/1075 [11:43<07:00,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.6ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 689/1075 [11:44<06:43,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 3.0ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 690/1075 [11:45<06:45,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.2ms\n",
            "Speed: 2.4ms preprocess, 17.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 691/1075 [11:47<07:13,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.8ms\n",
            "Speed: 2.4ms preprocess, 18.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 692/1075 [11:48<07:27,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.4ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 693/1075 [11:49<06:51,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 19.6ms\n",
            "Speed: 2.5ms preprocess, 19.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 694/1075 [11:50<06:39,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.5ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 695/1075 [11:51<06:24,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.4ms preprocess, 17.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 696/1075 [11:52<06:15,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.7ms\n",
            "Speed: 2.4ms preprocess, 17.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 697/1075 [11:53<06:11,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 2.6ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 698/1075 [11:54<06:03,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.4ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 699/1075 [11:54<05:47,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.7ms\n",
            "Speed: 2.4ms preprocess, 16.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 700/1075 [11:55<05:32,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 701/1075 [11:56<05:22,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.6ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 702/1075 [11:57<05:13,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.4ms preprocess, 17.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 703/1075 [11:58<05:12,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.5ms\n",
            "Speed: 2.6ms preprocess, 18.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 704/1075 [11:59<05:28,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 4.1ms preprocess, 16.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 705/1075 [12:00<05:47,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.9ms\n",
            "Speed: 2.5ms preprocess, 18.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 706/1075 [12:00<05:32,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 707/1075 [12:01<05:23,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.3ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 708/1075 [12:02<05:41,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.4ms preprocess, 14.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 709/1075 [12:03<05:47,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.3ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 710/1075 [12:04<05:48,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.6ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 711/1075 [12:05<06:03,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.4ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 712/1075 [12:06<06:07,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.5ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▋   | 713/1075 [12:07<06:03,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.4ms preprocess, 14.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▋   | 714/1075 [12:09<06:08,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.4ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 715/1075 [12:10<06:10,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 4.5ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 716/1075 [12:11<06:29,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 21.8ms\n",
            "Speed: 2.4ms preprocess, 21.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 717/1075 [12:12<07:14,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.4ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 718/1075 [12:13<06:48,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.4ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 719/1075 [12:14<06:34,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 19.3ms\n",
            "Speed: 2.4ms preprocess, 19.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 720/1075 [12:15<06:20,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 2.5ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 721/1075 [12:16<06:16,  1.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.6ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 722/1075 [12:17<06:15,  1.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 19.7ms\n",
            "Speed: 2.4ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 723/1075 [12:18<06:06,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 3.1ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 724/1075 [12:19<06:03,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 20.7ms\n",
            "Speed: 3.6ms preprocess, 20.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 725/1075 [12:21<06:10,  1.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.5ms preprocess, 14.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 726/1075 [12:21<06:00,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.4ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 727/1075 [12:23<06:18,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.9ms\n",
            "Speed: 2.7ms preprocess, 17.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 728/1075 [12:24<06:52,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 19.4ms\n",
            "Speed: 2.5ms preprocess, 19.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 729/1075 [12:25<06:55,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.3ms preprocess, 14.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 730/1075 [12:27<06:51,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 731/1075 [12:28<06:40,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.7ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 732/1075 [12:29<06:42,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.3ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 733/1075 [12:30<06:34,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 19.2ms\n",
            "Speed: 3.2ms preprocess, 19.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 734/1075 [12:31<06:33,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 7.4ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 735/1075 [12:32<06:36,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.5ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 736/1075 [12:33<06:28,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▊   | 737/1075 [12:35<06:27,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 3.5ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▊   | 738/1075 [12:36<07:07,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.8ms\n",
            "Speed: 2.5ms preprocess, 18.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▊   | 739/1075 [12:38<07:26,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 3.3ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 740/1075 [12:39<07:13,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.4ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 741/1075 [12:40<06:53,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 2.4ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 742/1075 [12:41<06:45,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.9ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 743/1075 [12:42<06:32,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.3ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 744/1075 [12:43<06:27,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.5ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 745/1075 [12:45<06:34,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.4ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 746/1075 [12:46<06:38,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 2.4ms preprocess, 13.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 747/1075 [12:47<06:26,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 2.4ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 748/1075 [12:48<06:58,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 22.8ms\n",
            "Speed: 2.3ms preprocess, 22.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 749/1075 [12:50<07:12,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.2ms\n",
            "Speed: 2.5ms preprocess, 17.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 750/1075 [12:51<06:44,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 2.4ms preprocess, 15.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 751/1075 [12:52<06:26,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.4ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 752/1075 [12:53<06:11,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 753/1075 [12:54<06:02,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.7ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 754/1075 [12:55<05:53,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.9ms\n",
            "Speed: 2.7ms preprocess, 17.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 755/1075 [12:56<05:58,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.4ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 756/1075 [12:57<05:57,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.3ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 757/1075 [12:59<05:52,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 758/1075 [13:00<06:04,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.5ms\n",
            "Speed: 2.6ms preprocess, 18.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 759/1075 [13:01<06:36,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 24.0ms\n",
            "Speed: 2.5ms preprocess, 24.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 760/1075 [13:02<06:18,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.7ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 761/1075 [13:03<06:10,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.4ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 762/1075 [13:05<06:00,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 2.7ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 763/1075 [13:06<05:55,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 764/1075 [13:07<05:49,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.1ms\n",
            "Speed: 2.5ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 765/1075 [13:08<05:44,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.4ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 766/1075 [13:09<05:43,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.2ms\n",
            "Speed: 2.5ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 767/1075 [13:10<05:37,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 768/1075 [13:11<05:35,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 15.1ms\n",
            "Speed: 2.9ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 769/1075 [13:12<05:47,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.9ms\n",
            "Speed: 2.5ms preprocess, 13.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 770/1075 [13:14<06:16,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 2.7ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 771/1075 [13:15<05:42,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.7ms\n",
            "Speed: 2.3ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 772/1075 [13:16<05:26,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 12.6ms\n",
            "Speed: 2.5ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 773/1075 [13:17<05:07,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.4ms\n",
            "Speed: 3.6ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 774/1075 [13:17<04:53,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 2.4ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 775/1075 [13:18<04:45,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.4ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 776/1075 [13:19<04:34,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 3.5ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 777/1075 [13:20<04:29,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 21.0ms\n",
            "Speed: 2.3ms preprocess, 21.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 778/1075 [13:21<04:26,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 2.4ms preprocess, 16.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 779/1075 [13:22<04:16,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 2.6ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 780/1075 [13:22<04:11,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 2.4ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 781/1075 [13:23<04:10,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.3ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 782/1075 [13:24<04:26,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 783/1075 [13:26<04:47,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 19.1ms\n",
            "Speed: 2.4ms preprocess, 19.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 784/1075 [13:27<04:49,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.4ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 785/1075 [13:27<04:36,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 2.4ms preprocess, 18.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 786/1075 [13:28<04:26,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.4ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 787/1075 [13:29<04:11,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.4ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 788/1075 [13:30<04:05,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 2.4ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 789/1075 [13:31<03:59,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.5ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 790/1075 [13:31<03:51,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 2.5ms preprocess, 16.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 791/1075 [13:32<03:36,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 2.4ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 792/1075 [13:33<03:22,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 2.4ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 793/1075 [13:33<03:11,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.4ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 794/1075 [13:34<03:04,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 795/1075 [13:35<03:07,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 796/1075 [13:35<02:58,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.4ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 797/1075 [13:36<02:58,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.7ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 798/1075 [13:36<03:02,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.0ms\n",
            "Speed: 2.4ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 799/1075 [13:37<02:55,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 2.5ms preprocess, 16.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 800/1075 [13:37<02:34,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 17.0ms\n",
            "Speed: 2.4ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 801/1075 [13:38<02:24,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.1ms\n",
            "Speed: 2.4ms preprocess, 18.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 802/1075 [13:38<02:25,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 25.0ms\n",
            "Speed: 2.5ms preprocess, 25.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 803/1075 [13:39<02:12,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 6.0ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 804/1075 [13:39<01:57,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 3.9ms preprocess, 18.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 805/1075 [13:39<01:52,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 12.0ms\n",
            "Speed: 2.6ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 806/1075 [13:40<01:49,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.4ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 807/1075 [13:40<01:43,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 13.8ms\n",
            "Speed: 2.9ms preprocess, 13.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 808/1075 [13:41<01:37,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 15.3ms\n",
            "Speed: 2.4ms preprocess, 15.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 809/1075 [13:41<01:34,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 14.7ms\n",
            "Speed: 2.9ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 810/1075 [13:41<01:30,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 3.2ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 811/1075 [13:41<01:28,  2.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.4ms preprocess, 15.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 812/1075 [13:42<01:25,  3.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 2.4ms preprocess, 18.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 813/1075 [13:42<01:27,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.0ms\n",
            "Speed: 2.4ms preprocess, 18.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 814/1075 [13:43<01:30,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.6ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 815/1075 [13:43<01:30,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 4.6ms preprocess, 26.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 816/1075 [13:43<01:36,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.8ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 817/1075 [13:44<01:35,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.4ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 818/1075 [13:44<01:38,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 2.7ms preprocess, 17.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 819/1075 [13:44<01:37,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.6ms preprocess, 14.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 820/1075 [13:45<01:39,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.5ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 821/1075 [13:45<01:38,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.5ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 822/1075 [13:46<01:36,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 3.2ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 823/1075 [13:46<01:35,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 6.9ms preprocess, 18.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 824/1075 [13:46<01:35,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.7ms\n",
            "Speed: 2.3ms preprocess, 17.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 825/1075 [13:47<01:33,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.4ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 826/1075 [13:47<01:35,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 22.5ms\n",
            "Speed: 2.7ms preprocess, 22.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 827/1075 [13:48<01:36,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.4ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 828/1075 [13:48<01:38,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 2.4ms preprocess, 16.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 829/1075 [13:48<01:39,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 2.6ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 830/1075 [13:49<01:44,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.4ms preprocess, 14.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 831/1075 [13:49<01:48,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.4ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 832/1075 [13:50<01:49,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 4.5ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 833/1075 [13:50<01:54,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.9ms\n",
            "Speed: 5.9ms preprocess, 18.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 834/1075 [13:51<01:57,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.9ms\n",
            "Speed: 2.8ms preprocess, 18.9ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 835/1075 [13:51<01:54,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.5ms preprocess, 15.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 836/1075 [13:52<01:46,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.4ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 837/1075 [13:52<01:43,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 2.6ms preprocess, 16.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 838/1075 [13:52<01:39,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.2ms\n",
            "Speed: 2.4ms preprocess, 18.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 839/1075 [13:53<01:43,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 840/1075 [13:53<01:48,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.4ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 841/1075 [13:54<01:50,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.4ms preprocess, 15.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 842/1075 [13:54<01:48,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 2.7ms preprocess, 16.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 843/1075 [13:55<01:46,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.8ms preprocess, 15.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 844/1075 [13:55<01:46,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 2.9ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 845/1075 [13:56<01:47,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 2.4ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 846/1075 [13:56<01:46,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.4ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 847/1075 [13:57<01:53,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 848/1075 [13:57<01:59,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 2.4ms preprocess, 13.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 849/1075 [13:58<01:58,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.5ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 850/1075 [13:58<01:57,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 2.5ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 851/1075 [13:59<01:56,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 22.0ms\n",
            "Speed: 2.9ms preprocess, 22.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 852/1075 [14:00<01:59,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 2.5ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 853/1075 [14:00<01:58,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.5ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 854/1075 [14:01<01:55,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 2.6ms preprocess, 15.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 855/1075 [14:01<01:58,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.4ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 856/1075 [14:02<02:08,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.4ms preprocess, 15.4ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 857/1075 [14:03<02:12,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.7ms\n",
            "Speed: 2.5ms preprocess, 17.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 858/1075 [14:03<02:22,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.7ms\n",
            "Speed: 2.4ms preprocess, 18.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 859/1075 [14:04<02:20,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.4ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 860/1075 [14:04<02:13,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.8ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 861/1075 [14:05<02:07,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.5ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 862/1075 [14:06<02:05,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.8ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 863/1075 [14:06<02:01,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.4ms preprocess, 13.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 864/1075 [14:07<02:02,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.6ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 865/1075 [14:07<01:58,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 4.3ms preprocess, 13.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 866/1075 [14:08<01:55,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 867/1075 [14:08<01:56,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 2.3ms preprocess, 15.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 868/1075 [14:09<01:51,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.4ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 869/1075 [14:09<01:53,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 3.0ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 870/1075 [14:10<01:46,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 871/1075 [14:10<01:43,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 2.4ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 872/1075 [14:11<01:38,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.7ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 873/1075 [14:12<01:55,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 2.5ms preprocess, 16.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████▏ | 874/1075 [14:12<02:05,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.4ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████▏ | 875/1075 [14:13<02:14,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.4ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████▏ | 876/1075 [14:14<02:25,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 2.8ms preprocess, 18.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 877/1075 [14:15<02:38,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.2ms\n",
            "Speed: 2.5ms preprocess, 17.2ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 878/1075 [14:16<03:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.3ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 879/1075 [14:17<02:52,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.5ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 880/1075 [14:18<02:43,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 2.6ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 881/1075 [14:18<02:36,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.5ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 882/1075 [14:19<02:33,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.5ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 883/1075 [14:20<02:30,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.4ms preprocess, 13.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 884/1075 [14:21<02:26,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.6ms preprocess, 15.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 885/1075 [14:21<02:24,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.6ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 886/1075 [14:22<02:19,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.8ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 887/1075 [14:23<02:13,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 3.2ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 888/1075 [14:23<02:08,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.7ms preprocess, 17.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 889/1075 [14:24<02:08,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.4ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 890/1075 [14:25<02:07,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.4ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 891/1075 [14:25<02:03,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 892/1075 [14:26<02:03,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 3.6ms preprocess, 15.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 893/1075 [14:27<02:16,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.2ms\n",
            "Speed: 2.6ms preprocess, 18.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 894/1075 [14:28<02:23,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.6ms\n",
            "Speed: 2.5ms preprocess, 17.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 895/1075 [14:29<02:22,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.5ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 896/1075 [14:29<02:18,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 6.3ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 897/1075 [14:30<02:15,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 2.5ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 898/1075 [14:31<02:09,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 2.7ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 899/1075 [14:32<02:09,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.4ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▎ | 900/1075 [14:32<02:05,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 2.4ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 901/1075 [14:33<02:00,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 2.2ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 902/1075 [14:33<01:58,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.3ms preprocess, 13.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 903/1075 [14:34<01:59,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.7ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 904/1075 [14:35<01:56,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.4ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 905/1075 [14:36<01:57,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 2.3ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 906/1075 [14:36<01:59,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.3ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 907/1075 [14:37<02:02,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.4ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 908/1075 [14:38<02:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.8ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 909/1075 [14:39<02:04,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 2.3ms preprocess, 16.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 910/1075 [14:40<02:15,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 23.6ms\n",
            "Speed: 2.6ms preprocess, 23.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 911/1075 [14:41<02:27,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.4ms preprocess, 17.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 912/1075 [14:41<02:18,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.4ms preprocess, 13.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 913/1075 [14:42<02:10,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 19.2ms\n",
            "Speed: 2.4ms preprocess, 19.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 914/1075 [14:43<02:07,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.4ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 915/1075 [14:44<02:01,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.8ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 916/1075 [14:44<01:55,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.5ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 917/1075 [14:45<01:51,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.4ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 918/1075 [14:46<01:52,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.3ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 919/1075 [14:46<01:51,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.9ms\n",
            "Speed: 2.4ms preprocess, 17.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 920/1075 [14:47<01:48,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 3.0ms preprocess, 15.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 921/1075 [14:48<01:46,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 2.5ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 922/1075 [14:48<01:44,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 2.4ms preprocess, 16.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 923/1075 [14:49<01:44,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 26.1ms\n",
            "Speed: 2.7ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 924/1075 [14:50<01:44,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.5ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 925/1075 [14:50<01:42,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.5ms preprocess, 17.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 926/1075 [14:51<01:46,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 22.6ms\n",
            "Speed: 3.4ms preprocess, 22.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 927/1075 [14:52<01:52,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.6ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 928/1075 [14:53<02:01,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 2.6ms preprocess, 16.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▋ | 929/1075 [14:54<01:53,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.4ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 930/1075 [14:54<01:46,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.5ms\n",
            "Speed: 2.4ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 931/1075 [14:55<01:40,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.0ms\n",
            "Speed: 2.5ms preprocess, 16.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 932/1075 [14:55<01:32,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 17.5ms\n",
            "Speed: 2.4ms preprocess, 17.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 933/1075 [14:56<01:27,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 18.9ms\n",
            "Speed: 2.7ms preprocess, 18.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 934/1075 [14:56<01:19,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 935/1075 [14:57<01:13,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 936/1075 [14:57<01:09,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.4ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 937/1075 [14:58<01:06,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.4ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 938/1075 [14:58<01:07,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 2.4ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 939/1075 [14:59<01:06,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.6ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 940/1075 [14:59<01:05,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.5ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 941/1075 [15:00<01:03,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.5ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 942/1075 [15:00<01:00,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 20.4ms\n",
            "Speed: 2.8ms preprocess, 20.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 943/1075 [15:00<00:57,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 2.4ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 944/1075 [15:01<00:53,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 2.4ms preprocess, 12.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 945/1075 [15:01<00:52,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 2.5ms preprocess, 15.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 946/1075 [15:02<00:50,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 6.3ms preprocess, 15.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 947/1075 [15:02<00:51,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.3ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 948/1075 [15:02<00:50,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.7ms preprocess, 13.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 949/1075 [15:03<00:48,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 950/1075 [15:03<00:46,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 19.4ms\n",
            "Speed: 2.4ms preprocess, 19.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 951/1075 [15:03<00:48,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 4.3ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▊ | 952/1075 [15:04<00:51,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 2.3ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▊ | 953/1075 [15:05<00:57,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 22.1ms\n",
            "Speed: 2.3ms preprocess, 22.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▊ | 954/1075 [15:05<01:03,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.8ms\n",
            "Speed: 2.4ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 955/1075 [15:06<01:10,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 2.5ms preprocess, 18.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 956/1075 [15:07<01:09,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 2.5ms preprocess, 13.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 957/1075 [15:07<01:11,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 13.7ms\n",
            "Speed: 2.4ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 958/1075 [15:08<01:10,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.4ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 959/1075 [15:08<01:09,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 13.3ms\n",
            "Speed: 2.3ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 960/1075 [15:09<01:10,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 14.4ms\n",
            "Speed: 2.4ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 961/1075 [15:10<01:13,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.3ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 962/1075 [15:10<01:14,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.3ms preprocess, 15.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 963/1075 [15:11<01:16,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 2.5ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 964/1075 [15:12<01:14,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 2.5ms preprocess, 17.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 965/1075 [15:13<01:14,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 966/1075 [15:13<01:14,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.5ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 967/1075 [15:14<01:14,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 20.9ms\n",
            "Speed: 2.3ms preprocess, 20.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 968/1075 [15:15<01:13,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 3 persons, 18.3ms\n",
            "Speed: 2.4ms preprocess, 18.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 969/1075 [15:15<01:11,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.4ms preprocess, 15.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 970/1075 [15:16<01:17,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 19.0ms\n",
            "Speed: 2.4ms preprocess, 19.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 971/1075 [15:17<01:25,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 2.4ms preprocess, 16.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 972/1075 [15:18<01:35,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 2.4ms preprocess, 16.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 973/1075 [15:19<01:32,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 974/1075 [15:20<01:31,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.7ms\n",
            "Speed: 2.5ms preprocess, 16.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 975/1075 [15:21<01:32,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.5ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 976/1075 [15:22<01:34,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 22.5ms\n",
            "Speed: 2.5ms preprocess, 22.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 977/1075 [15:23<01:35,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.5ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 978/1075 [15:24<01:34,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 2.4ms preprocess, 15.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 979/1075 [15:25<01:36,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 980/1075 [15:26<01:34,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 18.2ms\n",
            "Speed: 2.5ms preprocess, 18.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 981/1075 [15:27<01:31,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 16.0ms\n",
            "Speed: 2.6ms preprocess, 16.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 982/1075 [15:28<01:28,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 2.4ms preprocess, 15.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 983/1075 [15:29<01:39,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.6ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 984/1075 [15:31<01:48,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.3ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 985/1075 [15:32<01:41,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 2.6ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 986/1075 [15:33<01:37,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.5ms preprocess, 15.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 987/1075 [15:34<01:35,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 988/1075 [15:35<01:33,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.6ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 989/1075 [15:36<01:33,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.4ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 990/1075 [15:37<01:31,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.4ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 991/1075 [15:38<01:31,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.9ms preprocess, 15.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 992/1075 [15:39<01:32,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 3.2ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 993/1075 [15:40<01:31,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.8ms\n",
            "Speed: 2.4ms preprocess, 17.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 994/1075 [15:42<01:38,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.4ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 995/1075 [15:43<01:44,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.3ms preprocess, 15.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 996/1075 [15:45<01:43,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.6ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 997/1075 [15:46<01:40,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 20.4ms\n",
            "Speed: 2.4ms preprocess, 20.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 998/1075 [15:47<01:36,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.3ms preprocess, 14.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 999/1075 [15:48<01:34,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.7ms\n",
            "Speed: 3.4ms preprocess, 18.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1000/1075 [15:50<01:33,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.9ms preprocess, 15.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1001/1075 [15:51<01:30,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 2.5ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1002/1075 [15:52<01:27,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.4ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1003/1075 [15:53<01:28,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 40.2ms\n",
            "Speed: 2.4ms preprocess, 40.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1004/1075 [15:55<01:40,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 2.5ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 1005/1075 [15:56<01:33,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.4ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 1006/1075 [15:57<01:27,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 2.5ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▎| 1007/1075 [15:58<01:22,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 19.6ms\n",
            "Speed: 2.4ms preprocess, 19.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1008/1075 [16:00<01:20,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.3ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1009/1075 [16:01<01:18,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.3ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1010/1075 [16:02<01:17,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1011/1075 [16:03<01:14,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.4ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1012/1075 [16:04<01:13,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 2.4ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1013/1075 [16:06<01:16,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.3ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1014/1075 [16:07<01:22,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 2.6ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 1015/1075 [16:08<01:18,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.4ms preprocess, 14.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 1016/1075 [16:10<01:15,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.8ms preprocess, 14.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 1017/1075 [16:11<01:12,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.3ms preprocess, 14.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 1018/1075 [16:12<01:08,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 22.4ms\n",
            "Speed: 2.4ms preprocess, 22.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 1019/1075 [16:13<01:05,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 3.4ms preprocess, 15.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 1020/1075 [16:14<01:03,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 5.6ms preprocess, 16.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 1021/1075 [16:15<01:02,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.4ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 1022/1075 [16:16<01:00,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 1023/1075 [16:18<01:00,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.4ms preprocess, 14.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 1024/1075 [16:19<01:03,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.2ms\n",
            "Speed: 2.5ms preprocess, 18.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 1025/1075 [16:21<01:06,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.8ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 1026/1075 [16:22<01:01,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.4ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1027/1075 [16:23<01:00,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1028/1075 [16:24<00:57,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 20.7ms\n",
            "Speed: 3.3ms preprocess, 20.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1029/1075 [16:25<00:55,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.4ms preprocess, 13.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1030/1075 [16:26<00:54,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.8ms\n",
            "Speed: 2.4ms preprocess, 16.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1031/1075 [16:28<00:53,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1032/1075 [16:29<00:52,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1033/1075 [16:30<00:52,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 21.9ms\n",
            "Speed: 2.5ms preprocess, 21.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 1034/1075 [16:32<00:58,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 persons, 16.5ms\n",
            "Speed: 2.8ms preprocess, 16.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▋| 1035/1075 [16:33<00:55,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.4ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▋| 1036/1075 [16:35<00:51,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 2.4ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▋| 1037/1075 [16:36<00:47,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.5ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1038/1075 [16:37<00:45,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 4.4ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1039/1075 [16:38<00:44,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 2.7ms preprocess, 16.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1040/1075 [16:39<00:42,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 2.4ms preprocess, 16.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1041/1075 [16:40<00:41,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1042/1075 [16:42<00:39,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 3.1ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1043/1075 [16:43<00:41,  1.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.6ms\n",
            "Speed: 2.4ms preprocess, 17.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1044/1075 [16:45<00:44,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.6ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1045/1075 [16:46<00:41,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.5ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1046/1075 [16:47<00:38,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1047/1075 [16:48<00:35,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 2.4ms preprocess, 16.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 1048/1075 [16:50<00:33,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.5ms\n",
            "Speed: 2.5ms preprocess, 18.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1049/1075 [16:51<00:31,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.3ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1050/1075 [16:52<00:29,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.4ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1051/1075 [16:53<00:28,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.4ms preprocess, 14.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1052/1075 [16:54<00:26,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 20.9ms\n",
            "Speed: 2.9ms preprocess, 20.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1053/1075 [16:56<00:28,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.5ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1054/1075 [16:57<00:29,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.8ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1055/1075 [16:59<00:26,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.4ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1056/1075 [17:00<00:23,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 2.4ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1057/1075 [17:01<00:21,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.3ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 1058/1075 [17:02<00:18,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.3ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 1059/1075 [17:02<00:16,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.4ms preprocess, 14.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 1060/1075 [17:03<00:14,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 21.8ms\n",
            "Speed: 2.5ms preprocess, 21.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 1061/1075 [17:04<00:10,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.8ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1062/1075 [17:04<00:08,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.5ms preprocess, 14.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1063/1075 [17:04<00:06,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.4ms preprocess, 15.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1064/1075 [17:05<00:05,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1065/1075 [17:05<00:04,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.4ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1066/1075 [17:05<00:03,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.4ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1067/1075 [17:06<00:03,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 4.2ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1068/1075 [17:06<00:02,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 2.4ms preprocess, 15.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 1069/1075 [17:06<00:02,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.3ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 1070/1075 [17:07<00:01,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 19.4ms\n",
            "Speed: 4.1ms preprocess, 19.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 1071/1075 [17:07<00:01,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 17.7ms\n",
            "Speed: 2.6ms preprocess, 17.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 1072/1075 [17:08<00:01,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.4ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 1073/1075 [17:08<00:00,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 2.4ms preprocess, 16.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████▉| 1074/1075 [17:09<00:00,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 2.5ms preprocess, 18.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1075/1075 [17:09<00:00,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Путь к исходному видео: /content/input_video.mp4\n",
            "Путь к сохранённому видео с результатами YOLO:\n",
            "/content/output/output_yolo.mp4\n",
            "Путь к сохранённому видео с результатами второй модели:\n",
            "/content/output/output_second.mp4\n",
            "Средний IOU: 0.7690\n",
            "Средний MAE: 14.2874\n",
            "Средний MSE: 1164.7310\n",
            "Среднее время обработки кадра моделью YOLO: 0.0263 сек.\n",
            "Среднее время обработки кадра второй моделью: 0.8966 сек.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Распаковка\n",
        "!unzip videos.zip -d /content/test_videos/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtUrh9s8F1kX",
        "outputId": "4c815984-cf5a-4b20-813c-9f2dbad17ab2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  videos.zip\n",
            "  inflating: /content/test_videos/0LtLS9wROrk_E_000176_000204.mp4  \n",
            "  inflating: /content/test_videos/0LtLS9wROrk_E_000217_000300.mp4  \n",
            "  inflating: /content/test_videos/0LtLS9wROrk_E_000322_000417.mp4  \n",
            "  inflating: /content/test_videos/0LtLS9wROrk_E_000519_000594.mp4  \n",
            "  inflating: /content/test_videos/0LtLS9wROrk_E_000731_000738.mp4  \n",
            "  inflating: /content/test_videos/0LtLS9wROrk_E_000773_000802.mp4  \n",
            "  inflating: /content/test_videos/0LtLS9wROrk_E_000925_001024.mp4  \n",
            "  inflating: /content/test_videos/0MtilFKz4cA_E_001951_001980.mp4  \n",
            "  inflating: /content/test_videos/0MtilFKz4cA_E_002361_002435.mp4  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title def calculate_iou(box1, box2) / class VideoFrameCollector\n",
        "\n",
        "# Функция для вычисления IOU между двумя боксами\n",
        "def calculate_iou(box1, box2):\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    union = area1 + area2 - intersection\n",
        "    return intersection / union if union > 0 else 0\n",
        "\n",
        "\n",
        "class VideoFrameCollector:\n",
        "    def __init__(self, videos_dir, target_frames=1000, n_frames_per_video=10, max_frames_per_video=100):\n",
        "        \"\"\"\n",
        "        Инициализация сборщика кадров видео\n",
        "\n",
        "        :param videos_dir: Путь к директории с видеофайлами\n",
        "        :param target_frames: Общее целевое количество кадров\n",
        "        :param n_frames_per_video: Базовое количество кадров для каждого видео (N)\n",
        "        :param max_frames_per_video: Максимальное количество кадров на одно видео\n",
        "        \"\"\"\n",
        "        self.videos_dir = videos_dir\n",
        "        self.target_frames = target_frames\n",
        "        self.n_frames_per_video = n_frames_per_video\n",
        "        self.max_frames_per_video = max_frames_per_video\n",
        "        self.frames_list = []\n",
        "        self.processed_videos = []\n",
        "\n",
        "    def collect_frames(self, sort_by='length'):\n",
        "        \"\"\"\n",
        "        Сбор кадров из видеофайлов\n",
        "\n",
        "        :param sort_by: Критерий сортировки видео ('length' - по длине, 'name' - по имени)\n",
        "        \"\"\"\n",
        "        video_files = sorted(glob.glob(f'{self.videos_dir}/*.mp4'))\n",
        "        print(f\"Найдено видео: {len(video_files)}\")\n",
        "\n",
        "        # Сбор информации о видео\n",
        "        video_info = []\n",
        "        for video_path in video_files:\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            video_name = os.path.basename(video_path)\n",
        "            video_info.append({\n",
        "                'path': video_path,\n",
        "                'name': video_name,\n",
        "                'total_frames': total_frames\n",
        "            })\n",
        "            cap.release()\n",
        "\n",
        "        # Сортировка видео\n",
        "        if sort_by == 'length':\n",
        "            video_info.sort(key=lambda x: x['total_frames'], reverse=True)\n",
        "            print(\"Сортировка видео по длине (от самого длинного)\")\n",
        "        elif sort_by == 'name':\n",
        "            video_info.sort(key=lambda x: x['name'])\n",
        "            print(\"Сортировка видео по имени\")\n",
        "        else:\n",
        "            print(\"Используется порядок видео без сортировки\")\n",
        "\n",
        "        collected = 0\n",
        "        self.frames_list = []\n",
        "        self.processed_videos = []\n",
        "\n",
        "        # Сбор кадров\n",
        "        for video in video_info:\n",
        "            if collected >= self.target_frames:\n",
        "                break\n",
        "\n",
        "            # Определение количества кадров для этого видео\n",
        "            n_frames = min(\n",
        "                self.n_frames_per_video,\n",
        "                self.max_frames_per_video,\n",
        "                self.target_frames - collected\n",
        "            )\n",
        "\n",
        "            # Пропуск слишком коротких видео\n",
        "            if n_frames <= 0 or video['total_frames'] < 5:\n",
        "                continue\n",
        "\n",
        "            # Выбор кадров\n",
        "            frame_indices = np.linspace(0, video['total_frames']-1, n_frames, dtype=int)\n",
        "\n",
        "            cap = cv2.VideoCapture(video['path'])\n",
        "            for idx in frame_indices:\n",
        "                cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
        "                ret, frame = cap.read()\n",
        "                if ret:\n",
        "                    self.frames_list.append({\n",
        "                        'frame': frame,\n",
        "                        'video_name': video['name'],\n",
        "                        'frame_index': idx\n",
        "                    })\n",
        "            cap.release()\n",
        "\n",
        "            collected += n_frames\n",
        "            self.processed_videos.append({\n",
        "                'video_name': video['name'],\n",
        "                'frames_taken': n_frames,\n",
        "                'total_frames': video['total_frames']\n",
        "            })\n",
        "\n",
        "        print(f\"\\nСобрано кадров: {len(self.frames_list)}\")\n",
        "        print(\"Обработанные видео:\")\n",
        "        for vid in self.processed_videos:\n",
        "            print(f\" - {vid['video_name']}: {vid['frames_taken']}/{vid['total_frames']} кадров\")\n",
        "\n",
        "    def get_frames(self):\n",
        "        \"\"\"Возвращает собранные кадры\"\"\"\n",
        "        return self.frames_list\n",
        "\n",
        "    def get_processed_videos_info(self):\n",
        "        \"\"\"Возвращает информацию об обработанных видео\"\"\"\n",
        "        return self.processed_videos"
      ],
      "metadata": {
        "id": "FGuYJkzT7oTo",
        "cellView": "form"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "import torchvision\n",
        "from mmpose.apis import init_model, inference_topdown\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "\n",
        "# Устройство для вычислений\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Конфигурация\n",
        "VIDEOS_DIR = '/content/test_videos'\n",
        "TARGET_FRAMES = 1000\n",
        "N_FRAMES_PER_VIDEO = MAX_FRAMES_PER_VIDEO = 300\n",
        "V = 5\n",
        "\n",
        "out_yolo = cv2.VideoWriter(yolo_output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
        "out_second = cv2.VideoWriter(second_output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
        "\n",
        "POSE_CFG = 'mmpose/configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-256x192.py'\n",
        "POSE_CKPT = 'hrnet_w48_coco_256x192.pth'\n",
        "\n",
        "# Загрузка модели YOLO\n",
        "yolo_model = YOLO(\"yolo11n-pose.pt\")\n",
        "\n",
        "# Инициализация моделей\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "detector = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT').to(device)\n",
        "detector.eval()\n",
        "tracker = DeepSort(max_age=20, n_init=3)\n",
        "\n",
        "# Загрузка модели pose\n",
        "if not os.path.exists(POSE_CKPT):\n",
        "    os.system(f'wget -q https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth -O {POSE_CKPT}')\n",
        "pose_model = init_model(POSE_CFG, POSE_CKPT, device=device)\n",
        "\n",
        "# Скелет для визуализации\n",
        "skeleton = [[0,1],[0,2],[1,3],[2,4],[0,5],[0,6],\n",
        "            [5,7],[7,9],[6,8],[8,10],[5,11],[6,12],\n",
        "            [11,13],[13,15],[12,14],[14,16]]\n",
        "\n",
        "\n",
        "# Инициализация и сбор кадров\n",
        "collector = VideoFrameCollector(\n",
        "    videos_dir=VIDEOS_DIR,\n",
        "    target_frames=TARGET_FRAMES,\n",
        "    n_frames_per_video=N_FRAMES_PER_VIDEO,\n",
        "    max_frames_per_video=MAX_FRAMES_PER_VIDEO\n",
        ")\n",
        "\n",
        "collector.collect_frames(sort_by='length')  # Сортировать видео по длине\n",
        "\n",
        "# Получение собранных кадров\n",
        "frames_data = collector.get_frames()\n",
        "\n",
        "# Списки для хранения метрик\n",
        "iou_list = []\n",
        "mae_list = []\n",
        "mse_list = []\n",
        "yolo_times = []\n",
        "second_model_times = []\n",
        "# Обработка каждого кадра\n",
        "\n",
        "print(f\"▶️ Обработка видео: {os.path.basename(video_path)}, кадры {start_frame}-{end_frame-1}\")\n",
        "# Время обработки каждого кадра\n",
        "for frame_data in tqdm(frames_data):  # Упрощенный прогресс-бар\n",
        "    frame = frame_data['frame']\n",
        "\n",
        "    # Время обработки кадра для YOLO\n",
        "    start_time = time.time()\n",
        "    yolo_results = yolo_model.track(frame, persist=True, tracker=\"bytetrack.yaml\", verbose=False)\n",
        "    yolo_boxes = yolo_results[0].boxes.xyxy.cpu().numpy()\n",
        "    yolo_keypoints = yolo_results[0].keypoints.xy.cpu().numpy()\n",
        "    yolo_time = time.time() - start_time\n",
        "    yolo_times.append(yolo_time)\n",
        "\n",
        "    # Визуализация для YOLO (ограничиваем до V = 1)\n",
        "    for i in range(min(V, len(yolo_boxes))):  # Ограничиваем вывод до V объектов\n",
        "        box = yolo_boxes[i]\n",
        "        keypoints = yolo_keypoints[i]\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"ID: {track_id}\", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "        # Рисуем ключевые точки (позу)\n",
        "        for kp in keypoints:\n",
        "            cv2.circle(frame, tuple(kp.astype(int)), 5, (0, 0, 255), -1)\n",
        "\n",
        "        # Рисуем скелет\n",
        "        for p, q in skeleton:\n",
        "            if keypoints[p][0] > 0 and keypoints[q][0] > 0:\n",
        "                pt1 = tuple(keypoints[p].astype(int))\n",
        "                pt2 = tuple(keypoints[q].astype(int))\n",
        "                cv2.line(frame, pt1, pt2, (255, 0, 0), 2)\n",
        "\n",
        "    out_yolo.write(frame)\n",
        "\n",
        "        # Вторая модель: Faster R-CNN + HRNet\n",
        "    start_time = time.time()\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    input_tensor = torchvision.transforms.ToTensor()(frame_rgb).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = detector([input_tensor])[0]\n",
        "\n",
        "    boxes = outputs['boxes'].cpu().numpy()\n",
        "    scores = outputs['scores'].cpu().numpy()\n",
        "    labels = outputs['labels'].cpu().numpy()\n",
        "    mask = (scores > 0.5) & (labels == 1)\n",
        "    boxes = boxes[mask]\n",
        "    scores = scores[mask]  # Важно сохранить отфильтрованные scores\n",
        "\n",
        "    detections = []\n",
        "    for i, (box) in enumerate(boxes):\n",
        "        x1, y1, x2, y2 = box\n",
        "        w_box, h_box = x2 - x1, y2 - y1\n",
        "        detections.append(([int(x1), int(y1), int(w_box), int(h_box)], scores[i], 'person'))\n",
        "\n",
        "    tracks = tracker.update_tracks(detections, frame=frame)\n",
        "\n",
        "\n",
        "    # Собираем и сортируем подтверждённые треки по confidence\n",
        "    confirmed_tracks = []\n",
        "    for track in tracks:\n",
        "        if track.is_confirmed():\n",
        "            # Получаем confidence из последнего обнаружения трека\n",
        "            if hasattr(track, 'last_detection') and track.last_detection is not None:\n",
        "                confidence = track.last_detection.confidence\n",
        "            else:\n",
        "                # Если нет информации, используем минимальный confidence\n",
        "                confidence = 0.5\n",
        "            confirmed_tracks.append((confidence, track))\n",
        "\n",
        "    # Сортируем по уверенности (от высокой к низкой)\n",
        "    confirmed_tracks.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    # Берём только V самых уверенных треков\n",
        "    second_results = []\n",
        "    for i, (confidence, track) in enumerate(confirmed_tracks[:V]):\n",
        "        track_id = track.track_id\n",
        "        l, t, r, b = track.to_ltrb(orig=True)\n",
        "        second_results.append({'track_id': track_id, 'bbox': [l, t, r, b]})\n",
        "\n",
        "\n",
        "    for res in second_results:\n",
        "        l, t, r, b = res['bbox']\n",
        "        pose_res = inference_topdown(pose_model, frame, bboxes=np.array([[l, t, r, b]], dtype=np.float32))\n",
        "        pred_instances = pose_res[0].pred_instances\n",
        "        if pred_instances.keypoints is not None and len(pred_instances.keypoints) > 0:\n",
        "            res['keypoints'] = pred_instances.keypoints[0]\n",
        "\n",
        "    second_model_time = time.time() - start_time\n",
        "    second_model_times.append(second_model_time)\n",
        "\n",
        "    # Визуализация для второй модели\n",
        "    frame_second = frame.copy()\n",
        "    for res in second_results[:V-1]:  # Ограничиваем отображение до V человек\n",
        "        l, t, r, b = res['bbox']\n",
        "        cv2.rectangle(frame_second, (int(l), int(t)), (int(r), int(b)), (0, 255, 0), 2)\n",
        "        cv2.putText(frame_second, f\"ID: {res['track_id']}\", (int(l), int(t) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        if 'keypoints' in res:\n",
        "            for kp in res['keypoints']:\n",
        "                cv2.circle(frame_second, tuple(kp.astype(int)), 5, (0, 0, 255), -1)\n",
        "            for p, q in skeleton:\n",
        "                if res['keypoints'][p][0] > 0 and res['keypoints'][q][0] > 0:\n",
        "                    pt1 = tuple(res['keypoints'][p].astype(int))\n",
        "                    pt2 = tuple(res['keypoints'][q].astype(int))\n",
        "                    cv2.line(frame_second, pt1, pt2, (255, 0, 0), 2)\n",
        "\n",
        "    out_second.write(frame_second)\n",
        "\n",
        "    # Сопоставление детекций YOLO и второй модели\n",
        "    for yolo_box, yolo_kp in zip(yolo_boxes[:V], yolo_keypoints[:V]):\n",
        "        max_iou = 0\n",
        "        matched_second_res = None\n",
        "        for second_res in second_results:\n",
        "            second_box = second_res['bbox']\n",
        "            iou = calculate_iou(yolo_box, second_box)\n",
        "            if iou > max_iou:\n",
        "                max_iou = iou\n",
        "                matched_second_res = second_res\n",
        "\n",
        "        if max_iou > 0.5 and 'keypoints' in matched_second_res:  # Порог IOU\n",
        "            second_kp = matched_second_res['keypoints']\n",
        "            if yolo_kp.shape == (17, 2) and second_kp.shape == (17, 2):\n",
        "                # Разница между ключевыми точками\n",
        "                diff = yolo_kp - second_kp\n",
        "                mae = np.mean(np.abs(diff))\n",
        "                mse = np.mean(diff ** 2)\n",
        "\n",
        "                # Добавление метрик в список\n",
        "                iou_list.append(max_iou)\n",
        "                mae_list.append(mae)\n",
        "                mse_list.append(mse)\n",
        "\n",
        "# Закрытие видеофайлов и освобождение ресурсов\n",
        "cap.release()\n",
        "out_yolo.release()\n",
        "out_second.release()\n",
        "\n",
        "\n",
        "# Подсчёт средних метрик\n",
        "average_iou = np.mean(iou_list) if iou_list else 0\n",
        "average_mae = np.mean(mae_list) if mae_list else 0\n",
        "average_mse = np.mean(mse_list) if mse_list else 0\n",
        "average_yolo_time = np.mean(yolo_times) if yolo_times else 0\n",
        "average_second_model_time = np.mean(second_model_times) if second_model_times else 0\n",
        "print(\"____________result____________\")\n",
        "print(f\"Средний IOU: {average_iou:.4f}\")\n",
        "print(f\"Средний MAE: {average_mae:.4f}\")\n",
        "print(f\"Средний MSE: {average_mse:.4f}\")\n",
        "print(f\"Среднее время для YOLO: {average_yolo_time:.4f} секунд\")\n",
        "print(f\"Среднее время для второй модели: {average_second_model_time:.4f} секунд\")\n",
        "print(f\"Видео с результатами YOLO сохранено в: {yolo_output_path}\")\n",
        "print(f\"Видео с результатами второй модели сохранено в: {second_output_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "JPLZZ5NiAEXQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394,
          "referenced_widgets": [
            "63f8825faece466a9566c53625887ad3",
            "bbe6fb2f8b78419a884c8b6ff1470ff5",
            "2d5dc18d23264abf8f7124b69647ae69",
            "5571668f90f44c07bbed6da334eb863e",
            "b2511e84f9f143ee8d71c40159d6c643",
            "9f3ce161f53844568be3fdc52112d598",
            "e82dbdae8e3641d6b158924dace72459",
            "20c7dfa01da742a4a6b8456244cc6e21",
            "35c989b54b3847ea981aca252cd8d1f3",
            "7df3d1410a1d4abeadaab6253d678567",
            "c46bc61d52b84b8985046e8e323deeb4"
          ]
        },
        "outputId": "b28fa78a-ecf3-4686-a354-3f01f22ae63e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loads checkpoint by local backend from path: hrnet_w48_coco_256x192.pth\n",
            "Найдено видео: 9\n",
            "Сортировка видео по длине (от самого длинного)\n",
            "\n",
            "Собрано кадров: 1000\n",
            "Обработанные видео:\n",
            " - 0LtLS9wROrk_E_000925_001024.mp4: 300/2989 кадров\n",
            " - 0LtLS9wROrk_E_000322_000417.mp4: 300/2860 кадров\n",
            " - 0LtLS9wROrk_E_000217_000300.mp4: 300/2480 кадров\n",
            " - 0LtLS9wROrk_E_000519_000594.mp4: 100/2248 кадров\n",
            "▶️ Обработка видео: input_video.mp4, кадры 2152-3226\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63f8825faece466a9566c53625887ad3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "____________result____________\n",
            "Средний IOU: 0.7141\n",
            "Средний MAE: 12.8429\n",
            "Средний MSE: 1232.1106\n",
            "Среднее время для YOLO: 0.0200 секунд\n",
            "Среднее время для второй модели: 0.7013 секунд\n",
            "Видео с результатами YOLO сохранено в: /content/output/output_yolo.mp4\n",
            "Видео с результатами второй модели сохранено в: /content/output/output_second.mp4\n"
          ]
        }
      ]
    }
  ]
}